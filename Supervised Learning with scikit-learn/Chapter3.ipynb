{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Fine-tuning your model\n",
    "\n",
    "Having trained your model, your next task is to evaluate its performance. In this chapter, you will learn about some of the other metrics available in scikit-learn that will allow you to assess your model's performance in a more nuanced manner. Next, learn to optimize your classification and regression models using hyperparameter tuning."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# (1) How good is your model?\n",
    "\n",
    "## Classification metrics\n",
    "- Measuring model performance with accuracy\n",
    "    - Fraction of correctly classified samples\n",
    "\n",
    "## Class imbalence example: Emails\n",
    "- Spam classification\n",
    "    - 99% of emails are real; 1% of emails are spam\n",
    "- Could build a classifier that predicts ALL emails as real\n",
    "    - 99% accurate\n",
    "    - But horrible at actually classifying spam\n",
    "    - Fails at its original purpose\n",
    "- Need more nuanced metrics\n",
    "\n",
    "## Diagnosing classification predictions\n",
    "- Confusion matrix\n",
    "\n",
    "| | Predicted: | Predicted: |\n",
    "| :-: | :-: | :-: |\n",
    "| | Spam Email | Real Email |\n",
    "| Actual: Spam Email | True Positive | False Negative |\n",
    "| Acutal: Real Email | False Positive | True Negative |\n",
    "\n",
    "- Accuracy:\n",
    "$$\\frac{tp + tn}{tp + tn + fp + fn}$$\n",
    "\n",
    "## Metrics from the confusion matrix\n",
    "- Precision $\\frac{tp}{tp + fp}$\n",
    "- Recall $\\frac{tp}{tp + fn}$\n",
    "- F1score: $2\\cdot \\frac{precision * recall}{precision + recall}$\n",
    "- High precision: Not many real emails predicted as spam\n",
    "- High recall: Predicted most spam emails correctly\n",
    "\n",
    "## Confusion matrix in scikit-learn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "knn = KNeighborsClassifier(n_neighbors=8)\n",
    "X_trian, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "source": [
    "# Exercise I: Metrics for classification\n",
    "\n",
    "In Chapter 1, you evaluated the performance of your k-NN classifier based on its accuracy. However, as Andy discussed, accuracy is not always an informative metric. In this exercise, you will dive more deeply into evaluating the performance of binary classifiers by computing a confusion matrix and generating a classification report.\n",
    "\n",
    "You may have noticed in the video that the classification report consisted of three rows, and an additional support column. The support gives the number of samples of the true response that lie in that class - so in the video example, the support was the number of Republicans or Democrats in the test set on which the classification report was computed. The precision, recall, and f1-score columns, then, gave the respective metrics for that particular class.\n",
    "\n",
    "Here, you'll work with the [PIMA Indians](https://www.kaggle.com/uciml/pima-indians-diabetes-database) dataset obtained from the UCI Machine Learning Repository. The goal is to predict whether or not a given female patient will contract diabetes based on features such as BMI, age, and number of pregnancies. Therefore, it is a binary classification problem. A target value of `0` indicates that the patient does not have diabetes, while a value of `1` indicates that the patient does have diabetes. As in Chapters 1 and 2, the dataset has been preprocessed to deal with missing values.\n",
    "\n",
    "The dataset has been loaded into a DataFrame `df` and the feature and target variable arrays `X` and `y` have been created for you. In addition, `sklearn.model_selection.train_test_split` and `sklearn.neighbors.KNeighborsClassifier` have already been imported.\n",
    "\n",
    "Your job is to train a k-NN classifier to the data and evaluate its performance by generating a confusion matrix and classification report.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Import `classification_report` and `confusion_matrix` from `sklearn.metrics`.\n",
    "- Create training and testing sets with 40% of the data used for testing. Use a random state of `42`.\n",
    "- Instantiate a k-NN classifier with `6` neighbors, fit it to the training data, and predict the labels of the test set.\n",
    "- Compute and print the confusion matrix and classification report using the `confusion_matrix()` and `classification_report()` functions.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Instantiate a k-NN classifier: knn\n",
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels of the test data: y_pred\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Generate the confusion matrix and classification report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ]
}