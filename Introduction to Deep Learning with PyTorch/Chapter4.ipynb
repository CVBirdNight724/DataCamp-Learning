{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Using Convolutional Neural Networks\n",
    "\n",
    "In this last chapter, we learn how to make neural networks work well in practice, using concepts like regularization, batch-normalization and transfer learning."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# (1) The sequential module\n",
    "\n",
    "## AlexNet - declearing the modules\n",
    "\n",
    "```\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
    "        self.relu = nn.Relu(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, num_classes)\n",
    "```\n",
    "\n",
    "## AlexNet - forward() methods\n",
    "\n",
    "```\n",
    "def forward(self, x):\n",
    "    x = self.relu(self.conv1(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = self.relu(self.conv2(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = self.relu(self.conv3(x))\n",
    "    x = self.relu(self.conv4(x))\n",
    "    x = self.relu(self.conv5(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = self.avgpool(x)\n",
    "    x = x.view(x.size(0), 256 * 6 * 6)\n",
    "    x = self.relu(self.fc1(x))\n",
    "    x = self.relu(self.fc2(x))\n",
    "    return self.fc3(x)\n",
    "```\n",
    "\n",
    "## The sequential modulde - declaring the modules\n",
    "\n",
    "```\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes), )\n",
    "```\n",
    "\n",
    "## The sequential module - forward() method\n",
    "\n",
    "```\n",
    "def forward(self, x):\n",
    "    x = self.features(x)\n",
    "    x = self.avgpool(x)\n",
    "    x = x.view(x.size(0), 256 * 6 * 6)\n",
    "    x = self.classifier(x)\n",
    "    return x\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise I: Sequential module - init method\n",
    "\n",
    "Having learned about the sequential module, now is the time to see how you can convert a neural network that doesn't use sequential modules to one that uses them. We are giving the code to build the network in the usual way, and you are going to write the code for the same network using sequential modules.\n",
    "\n",
    "```\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(7 * 7 * 40, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 10) \n",
    "```\n",
    "\n",
    "We want the pooling layer to be used after the second and fourth convolutional layers, while the relu nonlinearity needs to be used after each layer except the last (fully-connected) layer. For the number of filters (kernels), stride, passing, number of channels and number of units, use the same numbers as above.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Declare all the layers needed for feature extraction in the `self.features`.\n",
    "- Declare the three linear layers in `self.classifier`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Declare all the layers for feature extraction\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1), \n",
    "            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True))\n",
    "        \n",
    "        # Declare all the layers for classification\n",
    "        self.classifier = nn.Sequential(nn.Linear(7 * 7 * 40, 1024),                  nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 2048), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048, 10))"
   ]
  },
  {
   "source": [
    "# Exercise II: Sequential module - forward() method\n",
    "\n",
    "Now, that you have defined all the modules that the network needs, it is time to apply them in the `forward()` method. For context, we are giving the code for the `forward()` method, if the net was written in the usual way.\n",
    "\n",
    "```\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.fc1 = nn.Linear(7 * 7 * 40, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 2048)\n",
    "        self.fc3 = nn.Linear(2048, 10) \n",
    "\n",
    "    def forward():\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.pool(self.conv2(x)))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.relu(self.pool(self.conv4(x)))\n",
    "        x = x.view(-1, 7 * 7 * 40)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "```\n",
    "\n",
    "Note: for evaluation purposes, the entire code of the class needs to be in the script. We are using the `__init__` method as you have coded it on the previous exercise, while you are going to code the `forward()` method here.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Extract the features from the images.\n",
    "- Squeeze the three spatial dimensions of the feature maps into one using the `view()` method.\n",
    "- Classify images based on the extracted features.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Declare all the layers for feature extraction\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1), \n",
    "            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=10, out_channels=20, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(2, 2), nn.ReLU(inplace=True))\n",
    "        \n",
    "        # Declare all the layers for classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(7 * 7 * 40, 1024), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 2048), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(2048, 10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "      \n",
    "        # Apply the feature extractor in the input\n",
    "        x = self.ReLU(self.features(x))\n",
    "        \n",
    "        # Squeeze the three spatial dimensions in one\n",
    "        x = x.view(-1, 7 * 7 * 40)\n",
    "        \n",
    "        # Classify the images\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  }
 ]
}