{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Convolutional Neural Networks (CNNs)\n",
    "\n",
    "In this third chapter, we introduce convolutional neural networks, learning how to train them and how to use them to make predictions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# (1) Convolution operator\n",
    "\n",
    "## Problem with the fully-connected neural networks\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-27 154142.png\">\n",
    "\n",
    "- Do you needto consider all the relations between the features?\n",
    "- Fully-connected neural networks are big and so very computationally inefficient.\n",
    "- They have so many parameters, and sor overfit.\n",
    "\n",
    "## Main ideas\n",
    "\n",
    "1) Units are connected with only a few units from the previous layer.\n",
    "2) Units share weights. \n",
    "\n",
    "## Convolving\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-27 154533.png\">\n",
    "\n",
    "## Activation map\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-27 154628.png\">\n",
    "\n",
    "<img src=\"imagr/Screenshot 2021-01-27 154717.png\">\n",
    "\n",
    "## Padding\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-27 154808.png\">\n",
    "\n",
    "Why padding:\n",
    "- Sizes get small too quickly\n",
    "- Corner pixel is only used once \n",
    "\n",
    "## Convolutions in PyTorch\n",
    "\n",
    "| **OOP-based (torch.nn)** | **Functional (torch.nn.functional)** |\n",
    "| :- | :- |\n",
    "| in_channel(int) - Number of channels in input | input - input tensor of shape (minibatch x in_channel x iH x iW |\n",
    "| out_channel(int) - Number of channels produced by the convolution | weight - filters of shape (out_channel x in_channel x kH x kW) |\n",
    "| kernel_size(int or tuple)  - Size of the convolving kernel | stride - the stride of the convolving kernel. Can be a single number or a tuple (sH, sW). Default: 1 |\n",
    "| padding(int or tuple, optional) - Zero- | padding - implicit zero paddings on both sides of the input. Can be a single number or a tuple (padH, padW) Default: 0 |\n",
    "\n",
    "## Convolutions in PyTorch\n",
    "\n",
    "```\n",
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "image = torch.rand(16, 3, 32, 32)\n",
    "conv_filter = torch.nn.Conv2d(in_channels=3, out_channels=1, kernel_size=5, stride=1, padding=0)\n",
    "output_feature = conv_filter(image)\n",
    "\n",
    "print(output_feature.shape)\n",
    "```\n",
    "\n",
    "```\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "image = torch.rand(16, 3, 32, 32)\n",
    "filter = torch.rand(1, 3, 5, 5)\n",
    "out_feat_F = F.conv2d(image, filter, stride=1, padding=0)\n",
    "\n",
    "print(out_feat_F.shape)\n",
    "```\n",
    "\n",
    "```\n",
    "conv_layer = torch.nn.Conv2d(in_channels=3, out_channels=5, kernel_size=5, stride=1, padding=1)\n",
    "output = conv_layer(image)\n",
    "print(output)\n",
    "```\n",
    "\n",
    "```\n",
    "filter = torch.rand(3, 5, 5, 5)\n",
    "output_feature = F.conv2d(image, filter, stride=1, padding=1)\n",
    "print(output_feature.shape)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise I: Convolution operator - OOP way\n",
    "\n",
    "Let's kick off this chapter by using convolution operator from the `torch.nn` package. You are going to create a random tensor which will represent your image and random filters to convolve the image with. Then you'll apply those images.\n",
    "\n",
    "The `torch` library and the `torch.nn` package have already been imported for you.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Create 10 images with shape `(1, 28, 28)`.\n",
    "- Build `6` convolutional filters of size `(3, 3)` with stride set to `1` and padding set to `1`.\n",
    "- Apply the filters in the image and print the shape of the feature map."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 10 random images of shape (1, 28, 28)\n",
    "images = torch.rand(10, 1, 28, 28)\n",
    "\n",
    "# Build 6 conv. filters\n",
    "conv_filters = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Convolve the image with the filters\n",
    "output_feature = conv_filters(images)\n",
    "print(output_feature.shape)"
   ]
  },
  {
   "source": [
    "# Exercise II: Convolution operator - Functional way\n",
    "\n",
    "While I and most of PyTorch practitioners love the `torch.nn` package (OOP way), other practitioners prefer building neural network models in a more functional way, using `torch.nn.functional`. More importantly, it is possible to mix the concepts and use both libraries at the same time (we have already done it in the previous chapter). You are going to build the same neural network you built in the previous exercise, but this time using the functional way.\n",
    "\n",
    "As before, we have already imported the torch library and `torch.nn.functional` as `F`.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Create 10 random images with shape `(1, 28, 28)`.\n",
    "- Create 6 random filters with shape `(1, 3, 3)`.\n",
    "- Convolve the images with the filters."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 10 random images\n",
    "image = torch.rand(10, 1, 28, 28)\n",
    "\n",
    "# Create 6 filters\n",
    "filters = torch.rand(6, 1, 3, 3)\n",
    "\n",
    "# Convolve the image with the filters\n",
    "output_feature = F.conv2d(image, filters, stride=1, padding=1)\n",
    "print(output_feature.shape)"
   ]
  },
  {
   "source": [
    "# (2) Pooling operators\n",
    "\n",
    "## Pooling layer\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-27 164056.png\">\n",
    "\n",
    "## Max-Pooling\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-27 164253.png\">\n",
    "\n",
    "## Average-Pooling\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-27 164342.png\">\n",
    "\n",
    "- Typically used deeper in the network\n",
    "\n",
    "## Max-pooling in PyTorch\n",
    "\n",
    "OOP\n",
    "\n",
    "```\n",
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "im = torch.Tensor([[[[3, 1, 3, 5], [6, 0, 7, 9], [3, 2, 1, 4], [0, 2, 4, 4]]]])\n",
    "max_pooling = torch.nn.MaxPool2d(2)\n",
    "output_feature = max_pooling(im)\n",
    "print(output_feature)\n",
    "```\n",
    "\n",
    "Functional\n",
    "\n",
    "```\n",
    "import torch\n",
    "import torch.nn.Functional as F\n",
    "\n",
    "im = torch.Tensor([[[[3, 1, 3, 5], [6, 0, 7, 9], [3, 2, 1, 4], [0, 2, 4, 3]]]])\n",
    "output_feature_F = F.max_pool2d(im, 2)\n",
    "print(output_feature_F)\n",
    "```\n",
    "\n",
    "\n",
    "## Average pooling in PyTorch\n",
    "\n",
    "OOP\n",
    "\n",
    "```\n",
    "image torch\n",
    "image torch.nn\n",
    "\n",
    "im = torch.Tensor([[[[3, 1, 3, 5], [6, 0, 7, 9], [3, 2, 1, 4], [0, 2, 4, 3]]]])\n",
    "\n",
    "avg_pooling = torch.nn.AvgPool2d(2)\n",
    "output_feature = avg_pooling(im)\n",
    "print(output_feature)\n",
    "```\n",
    "\n",
    "Functional\n",
    "\n",
    "```\n",
    "import torch\n",
    "import torch\n",
    "\n",
    "im = torch.Tensor([[[[3, 1, 3, 5], [6, 0, 7, 9], [3, 2, 1, 4], [0, 2, 4, 3]]]])\n",
    "\n",
    "output_feature_F = F.avg_pool2d(im, 2)\n",
    "print(output_feature_F)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise III: Max-pooling operator\n",
    "\n",
    "Here you are going to practice using max-pooling in both OOP and functional way, and see for yourself that the produced results are the same. We have already created and printed the image for you, and imported `torch` library in addition to `torch.nn` and `torch.nn.Functional as F` packages.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Build a max-pooling operator with size `2`.\n",
    "- Apply the max-pooling operator in the image (loaded as `im`).\n",
    "- Use a max-pooling operator in functional way in the image.\n",
    "- Print the results of both cases."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pooling operator with size `2`.\n",
    "max_pooling = torch.nn.MaxPool2d(2)\n",
    "\n",
    "# Apply the pooling operator\n",
    "output_feature = max_pooling(im)\n",
    "\n",
    "# Use pooling operator in the image\n",
    "output_feature_F = F.max_pool2d(im, 2)\n",
    "\n",
    "# print the results of both cases\n",
    "print(output_feature)\n",
    "print(output_feature_F)"
   ]
  },
  {
   "source": [
    "# Exercise IV: Average-pooling operator\n",
    "\n",
    "After coding the max-pooling operator, you are now going to code the average-pooling operator. You just need to replace max-pooling with average pooling.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Build an average-pooling operator with size `2`.\n",
    "- Apply the average-pooling operator in the image.\n",
    "- Use an average-pooling operator in functional way in the image, called `im`.\n",
    "- Print the results of both cases.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pooling operator with size `2`.\n",
    "avg_pooling = torch.nn.AvgPool2d(2)\n",
    "\n",
    "# Apply the pooling operator\n",
    "output_feature = avg_pooling(im)\n",
    "\n",
    "# Use pooling operator in the image\n",
    "output_feature_F = F.avg_pool2d(im, 2)\n",
    "\n",
    "# print the results of both cases\n",
    "print(output_feature)\n",
    "print(output_feature_F)"
   ]
  },
  {
   "source": [
    "# (3) Convolutional Neural Networks\n",
    "\n",
    "## AlexNet\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-27 170621.png\">\n",
    "\n",
    "## Transformation   \n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-25 152946.png\">\n",
    "\n",
    "## AlexNet in PyTorch\n",
    "\n",
    "```\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
    "        self.relu = nn.Relu(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(384, 256, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, num_classes)\n",
    "```\n",
    "\n",
    "## The forward method\n",
    "\n",
    "```\n",
    "def forward(self, x):\n",
    "    x = self.relu(self.conv1(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = self.relu(self.conv2(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = self.relu(self.conv3(x))\n",
    "    x = self.relu(self.conv4(x))\n",
    "    x = self.relu(self.conv5(x))\n",
    "    x = self.maxpool(x)\n",
    "    x = self.avgpool(x)\n",
    "    x = x.view(x.size(0), 256 * 6 * 6)\n",
    "    x = self.relu(self.fc1(x))\n",
    "    x = self.relu(self.fc2(x))\n",
    "    return self.fc3(x)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise V: Your first CNN - __init__ method\n",
    "\n",
    "You are going to build your first convolutional neural network. You're going to use the `MNIST` dataset as the dataset, which is made of handwritten digits from 0 to 9. The convolutional neural network is going to have 2 convolutional layers, each followed by a `ReLU` nonlinearity, and a fully connected layer. We have already imported `torch` and `torch.nn` as `nn`. Remember that each pooling layer halves both the height and the width of the image, so by using `2` pooling layers, the height and width are `1/4` of the original sizes. `MNIST` images have shape `(1, 28, 28)`\n",
    "\n",
    "For the moment, you are going to implement the `__init__` method of the net. In the next exercise, you will implement the `.forward()` method.\n",
    "\n",
    "NB: We need **2** pooling layers, but we only need to **instantiate a pooling layer once**, because each pooling layer will have the same configuration. Instead, we will use `self.pool` twice in the next exercise.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Instantiate two convolutional filters: the first one should have `5` channels, while the second one should have `10` channels. The `kernel_size` for both of them should be `3`, and both should use `padding=1`. Use the names of the arguments (instead of using `1`, use `padding=1`).\n",
    "- Instantiate a `ReLU()` nonlinearity.\n",
    "- Instantiate a max pooling layer which halves the size of the image in both directions.\n",
    "- Instantiate a fully connected layer which connects the units with the number of classes (we are using `MNIST`, so there are `10` classes)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Instantiate two convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Instantiate the ReLU nonlinearity\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Instantiate a max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Instantiate a fully connected layer\n",
    "        self.fc = nn.Linear(7 * 7 * 10, 10)"
   ]
  },
  {
   "source": [
    "# Exercise VI: Your first CNN - forward() method\n",
    "\n",
    "Now that you have declared all the parameters of your CNN, all you need to do is to implement the net's `forward()` method, and voila, you have your very first PyTorch CNN.\n",
    "\n",
    "Note: for evaluation purposes, the entire code of the class needs to be in the script. We are using the `__init__` method as you have coded it on the previous exercise, while you are going to code the `.forward()` method here.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Apply the first `convolutional` layer, followed by the `relu` nonlinearity, then in the next line apply max-pooling layer.\n",
    "- Apply the second `convolutional` layer, followed by the `relu` nonlinearity, then in the next line apply max-pooling layer.\n",
    "- Transform the feature map from `4` dimensional to `2` dimensional space. The first dimension contains the batch size `(-1)`, deduct the second dimension, by multiplying the values for `height`, `width` and `depth`.\n",
    "- Apply the `fully-connected` layer and return the result."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "\t\t\n",
    "        # Instantiate the ReLU nonlinearity\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Instantiate two convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=5, out_channels=10, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Instantiate a max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Instantiate a fully connected layer\n",
    "        self.fc = nn.Linear(7 * 7 * 10, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Apply conv followd by relu, then in next line pool\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Apply conv followd by relu, then in next line pool\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Prepare the image for the fully connected layer\n",
    "        x = x.view(-1, 7 * 7 * 10)\n",
    "\n",
    "        # Apply the fully connected layer and return the result\n",
    "        return self.fc(x)"
   ]
  },
  {
   "source": [
    "# (4) Training Convolutional Neural Networks\n",
    "\n",
    "## Imports\n",
    "\n",
    "```\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "```\n",
    "\n",
    "## Dataloaders\n",
    "\n",
    "```\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.Dataloader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.Dataloader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
    "```\n",
    "\n",
    "## Building a CNN\n",
    "\n",
    "```\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, nun_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc = nn.Linear(128 * 4 * 4, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        return self.fc(x)\n",
    "```\n",
    "\n",
    "## Optimizer and Loss Function\n",
    "\n",
    "```\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameter(), lr=3e-4)\n",
    "```\n",
    "\n",
    "## Training a CNN\n",
    "\n",
    "```\n",
    "for epoch in range(10):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print('Finished Training')\n",
    "```\n",
    "\n",
    "## Evaluating the results\n",
    "\n",
    "```\n",
    "correct, total = 0, 0\n",
    "predictions = []\n",
    "net.eval()\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    inputs, labels = data\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions.append(outputs)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise VII: Training CNNs\n",
    "\n",
    "Similarly to what you did in Chapter 2, you are going to train a neural network. This time however, you will train the CNN you built in the previous lesson, instead of a fully connected network. The packages you need have been imported for you and the network (called `net`) instantiated. The cross-entropy loss function (called `criterion`) and the Adam optimizer (called `optimizer`) are also available. We have subsampled the training set so that the training goes faster, and you are going to use a single epoch.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Compute the predictions from the `net`.\n",
    "- Using the `predictions` and the `labels`, compute the loss function.\n",
    "- Compute the gradients for each weight.\n",
    "- Update the weights using the `optimizer`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, data in enumerate(train_loader, 0):\n",
    "    inputs, labels = data\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Compute the forward pass\n",
    "    outputs = net(inputs)\n",
    "        \n",
    "    # Compute the loss function\n",
    "    loss = criterion(outputs, labels)\n",
    "        \n",
    "    # Compute the gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the weights\n",
    "    optimizer.step()"
   ]
  },
  {
   "source": [
    "# Exercise VIII: Using CNNs to make predictions\n",
    "\n",
    "Building and training neural networks is a very exciting job (trust me, I do it every day)! However, the main utility of neural networks is to make predictions. This is the entire reason why the field of deep learning has bloomed in the last few years, as neural networks predictions are extremely accurate. On this exercise, we are going to use the convolutional neural network you already trained in order to make predictions on the `MNIST` dataset.\n",
    "\n",
    "Remember that `torch.max()` takes two arguments: -`output.data` - the tensor which contains the data.\n",
    "\n",
    "    - Either `1` to do `argmax` or `0` to do `max`.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Iterate over the given `test_loader`, saving the results of each iteration in `data`.\n",
    "- Get the image and label from the data tuple, storing the results in `image` and `label`.\n",
    "- Make a forward pass in the net using your `image`.\n",
    "- Get the net prediction using `torch.max()` function.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the data in the test_loader\n",
    "for i, data in enumerate(test_loader):\n",
    "\n",
    "    # Get the image and label from data\n",
    "    image, label = data\n",
    "\n",
    "    # Make a forward pass in the net with your image\n",
    "    output = net(image)\n",
    "\n",
    "    # Argmax the results of the net\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    if predicted == label:\n",
    "        print(\"Yipes, your net made the right prediction \" + str(predicted))\n",
    "    else:\n",
    "        print(\"Your net prediction was \" + str(predicted) + \", but the correct label is: \" + str(label))"
   ]
  }
 ]
}