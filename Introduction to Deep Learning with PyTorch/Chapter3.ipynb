{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Convolutional Neural Networks (CNNs)\n",
    "\n",
    "In this third chapter, we introduce convolutional neural networks, learning how to train them and how to use them to make predictions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# (1) Convolution operator\n",
    "\n",
    "## Problem with the fully-connected neural networks\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-27 154142.png\">\n",
    "\n",
    "- Do you needto consider all the relations between the features?\n",
    "- Fully-connected neural networks are big and so very computationally inefficient.\n",
    "- They have so many parameters, and sor overfit.\n",
    "\n",
    "## Main ideas\n",
    "\n",
    "1) Units are connected with only a few units from the previous layer.\n",
    "2) Units share weights. \n",
    "\n",
    "## Convolving\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-27 154533.png\">\n",
    "\n",
    "## Activation map\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-27 154628.png\">\n",
    "\n",
    "<img src=\"imagr/Screenshot 2021-01-27 154717.png\">\n",
    "\n",
    "## Padding\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-27 154808.png\">\n",
    "\n",
    "Why padding:\n",
    "- Sizes get small too quickly\n",
    "- Corner pixel is only used once \n",
    "\n",
    "## Convolutions in PyTorch\n",
    "\n",
    "| **OOP-based (torch.nn)** | **Functional (torch.nn.functional)** |\n",
    "| :- | :- |\n",
    "| in_channel(int) - Number of channels in input | input - input tensor of shape (minibatch x in_channel x iH x iW |\n",
    "| out_channel(int) - Number of channels produced by the convolution | weight - filters of shape (out_channel x in_channel x kH x kW) |\n",
    "| kernel_size(int or tuple)  - Size of the convolving kernel | stride - the stride of the convolving kernel. Can be a single number or a tuple (sH, sW). Default: 1 |\n",
    "| padding(int or tuple, optional) - Zero- | padding - implicit zero paddings on both sides of the input. Can be a single number or a tuple (padH, padW) Default: 0 |\n",
    "\n",
    "## Convolutions in PyTorch\n",
    "\n",
    "```\n",
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "image = torch.rand(16, 3, 32, 32)\n",
    "conv_filter = torch.nn.Conv2d(in_channels=3, out_channels=1, kernel_size=5, stride=1, padding=0)\n",
    "output_feature = conv_filter(image)\n",
    "\n",
    "print(output_feature.shape)\n",
    "```\n",
    "\n",
    "```\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "image = torch.rand(16, 3, 32, 32)\n",
    "filter = torch.rand(1, 3, 5, 5)\n",
    "out_feat_F = F.conv2d(image, filter, stride=1, padding=0)\n",
    "\n",
    "print(out_feat_F.shape)\n",
    "```\n",
    "\n",
    "```\n",
    "conv_layer = torch.nn.Conv2d(in_channels=3, out_channels=5, kernel_size=5, stride=1, padding=1)\n",
    "output = conv_layer(image)\n",
    "print(output)\n",
    "```\n",
    "\n",
    "```\n",
    "filter = torch.rand(3, 5, 5, 5)\n",
    "output_feature = F.conv2d(image, filter, stride=1, padding=1)\n",
    "print(output_feature.shape)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise I: Convolution operator - OOP way\n",
    "\n",
    "Let's kick off this chapter by using convolution operator from the `torch.nn` package. You are going to create a random tensor which will represent your image and random filters to convolve the image with. Then you'll apply those images.\n",
    "\n",
    "The `torch` library and the `torch.nn` package have already been imported for you.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Create 10 images with shape `(1, 28, 28)`.\n",
    "- Build `6` convolutional filters of size `(3, 3)` with stride set to `1` and padding set to `1`.\n",
    "- Apply the filters in the image and print the shape of the feature map."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 10 random images of shape (1, 28, 28)\n",
    "images = torch.rand(10, 1, 28, 28)\n",
    "\n",
    "# Build 6 conv. filters\n",
    "conv_filters = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Convolve the image with the filters\n",
    "output_feature = conv_filters(images)\n",
    "print(output_feature.shape)"
   ]
  },
  {
   "source": [
    "# Exercise II: Convolution operator - Functional way\n",
    "\n",
    "While I and most of PyTorch practitioners love the `torch.nn` package (OOP way), other practitioners prefer building neural network models in a more functional way, using `torch.nn.functional`. More importantly, it is possible to mix the concepts and use both libraries at the same time (we have already done it in the previous chapter). You are going to build the same neural network you built in the previous exercise, but this time using the functional way.\n",
    "\n",
    "As before, we have already imported the torch library and `torch.nn.functional` as `F`.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Create 10 random images with shape `(1, 28, 28)`.\n",
    "- Create 6 random filters with shape `(1, 3, 3)`.\n",
    "- Convolve the images with the filters."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 10 random images\n",
    "image = torch.rand(10, 1, 28, 28)\n",
    "\n",
    "# Create 6 filters\n",
    "filters = torch.rand(6, 1, 3, 3)\n",
    "\n",
    "# Convolve the image with the filters\n",
    "output_feature = F.conv2d(image, filters, stride=1, padding=1)\n",
    "print(output_feature.shape)"
   ]
  }
 ]
}