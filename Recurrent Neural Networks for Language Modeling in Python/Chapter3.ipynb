{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Multi-class classification\n",
    "\n",
    "Next, in this chapter you will learn how to prepare data for the multi-class classification task, as well as the differences between multi-class classification and binary classification (sentiment analysis). Finally, you will learn how to create models and measure their performance with Keras."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# (1) Data pre-processing\n",
    "\n",
    "## Text classification\n",
    "Application of text classification\n",
    "- Automatic news classification\n",
    "- Document classification\n",
    "- Queue segmentation for customer support\n",
    "\n",
    "## Changes from binary classification\n",
    "What change from binary to multi class:\n",
    "- Shape of the output variable `y`\n",
    "- Number of units on the output layer\n",
    "- Activation function on the output layer\n",
    "- Loss function\n",
    "\n",
    "## Changes from binary classification\n",
    "Shape of the output variable `y`:\n",
    "\n",
    "- One-hot encoding of the classes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: num_classes = 3\n",
    "y[0] = [0, 1, 0]\n",
    "y.shape = (N, num_classes)"
   ]
  },
  {
   "source": [
    "## Change from binary classification\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='image/Screenshot 2021-02-12 191952.png'>\n",
    "</p>\n",
    "\n",
    "Activation function on the output layer:\n",
    "\n",
    "- `softmax` gives the probability of every class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "source": [
    "Loss function:\n",
    "- Instead of binary, we use categorical cross-entropy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy')"
   ]
  },
  {
   "source": [
    "## Preparing text categories for keras"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [\"sports\", \"economy\", \"data_science\", \"sports\", \"finance\"]\n",
    "# Transform to pandas series object\n",
    "y_series = pd.Series(y, dtype=\"category\")\n",
    "# Print the category codes\n",
    "print(y_series.cat.codes)"
   ]
  },
  {
   "source": [
    "## Pre-processing y"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y = np.array([0, 1, 2])\n",
    "\n",
    "# Change to categorical\n",
    "y_prep = to_categorical(y)\n",
    "print(y_prep)"
   ]
  },
  {
   "source": [
    "# Exercise I: Prepare label vectors\n",
    "In the video exercise, you learned the differences between binary classification and multi-class classification. You learned that there are some modifications to the data preparation process that need to be done before training the models.\n",
    "\n",
    "In this exercise, you will prepare a raw dataset with labels given as text. The data is given as a `pandas.DataFrame` called `df`, with two columns: `text` with the text data and `label` with the label names. Your task is to make all the necessary transformations to the labels: change string to number and one-hot encode.\n",
    "\n",
    "The module `pandas` as `pd` and the function `to_categorical()` from `keras.utils.np_utils` are already loaded in the environment and the first lines of the dataset is printed on the console for you to see.\n",
    "\n",
    "### Instructions 1/3\n",
    "\n",
    "- Get the attribute `.cat.codes` of the column `label` contained on data frame `df` and print its shape."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the numerical ids of column label\n",
    "numerical_ids = df.label.cat.codes\n",
    "\n",
    "# Print initial shape\n",
    "print(numerical_ids.shape)"
   ]
  },
  {
   "source": [
    "### Instructions 2/3\n",
    "\n",
    "- One-hot encode the vector using the `to_categorical()` function and store the results in `Y` while printing the new shape."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the numerical ids of column label\n",
    "numerical_ids = df.label.cat.codes\n",
    "\n",
    "# Print initial shape\n",
    "print(numerical_ids.shape)\n",
    "\n",
    "# One-hot encode the indexes\n",
    "Y = to_categorical(numerical_ids)\n",
    "\n",
    "# Check the new shape of the variable\n",
    "print(Y.shape)"
   ]
  },
  {
   "source": [
    "### Instructions 3/3\n",
    "\n",
    "- Print the first 5 rows of the variable `Y`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the numerical ids of column label\n",
    "numerical_ids = df.label.cat.codes\n",
    "\n",
    "# Print initial shape\n",
    "print(numerical_ids.shape)\n",
    "\n",
    "# One-hot encode the indexes\n",
    "Y = to_categorical(numerical_ids)\n",
    "\n",
    "# Check the new shape of the variable\n",
    "print(Y.shape)\n",
    "\n",
    "# Print the first 5 rows\n",
    "print(Y[:5])"
   ]
  },
  {
   "source": [
    "# Exercise II: Pre-process data\n",
    "\n",
    "You learned the differences for pre-processing the data in the case of multi-class classification. Let's put that into practice by preprocessing the data in anticipation of creating a simple multi-class classification model.\n",
    "\n",
    "The dataset is loaded in the variable `news_dataset`, and has the following attributes:\n",
    "\n",
    "- `news_dataset.data`: array with texts\n",
    "- `news_dataset.target`: array with target categories as numerical indexes\n",
    "\n",
    "The sample data contains 5,000 observations.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Instantiate the `Tokenizer` class on the `tokenizer` variable.\n",
    "- Fit the `tokenizer` variable on the text data.\n",
    "- Use the `.texts_to_sequences()` method on the text data.\n",
    "- Use the `to_categorical()` function to prepare the target indexes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(news_dataset.data)\n",
    "\n",
    "# Prepare the data\n",
    "prep_data = tokenizer.texts_to_sequences(news_dataset.data)\n",
    "prep_data = pad_sequences(prep_data, maxlen=200)\n",
    "\n",
    "# Prepare the labels\n",
    "prep_labels = to_categorical(news_dataset.target)\n",
    "\n",
    "# Print the shapes\n",
    "print(prep_data.shape)\n",
    "print(prep_labels.shape)"
   ]
  },
  {
   "source": [
    "# (2) Transfer learning for language models\n",
    "\n",
    "## The idea behind transfer learning\n",
    "Transfer learning:\n",
    "- Start with better than random initial weights\n",
    "- Use models trained on very big datasets\n",
    "- \"Open-source\" data science models\n",
    "\n",
    "## Available architectures\n",
    "Base example: `I really loved this movie`\n",
    "\n",
    "- Word2Vec\n",
    "    - Continuous Bags of words (CBOW) `X = [I, really, this, movie], y = loved`\n",
    "    - Skip-gram `X = loved, y = [I, really, this, movie]`\n",
    "- FastText `X= [I, rea, eal, all, lly, really, ...], y = loved`\n",
    "    - Uses word and n-grams of chars\n",
    "- ELMo `X = [I, really, loved, this], y = movie`\n",
    "    - Uses words, embeddings per context\n",
    "    - Uses Deep bidirectional language models (biLM)\n",
    "- Word2Vec and FastText are FastText are available on package `gensim` and ELMo on `tensorflow_hub`\n",
    "\n",
    "## Example using Word2Vec"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "# Train the model\n",
    "w2v_model = word2vec.Word2Vec(tokenized_corpus, size=embedding_dim,\n",
    "                                window=neighbor_words_num, iter=100)\n",
    "# Get top 3 similar words to \"Captain\"\n",
    "w2v_model.wv.model_similar([\"captain\"], topn=3)"
   ]
  },
  {
   "source": [
    "## Example using FastText"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.model import fasttext\n",
    "# Instantiate the model\n",
    "ft_model = fasttext.FastText(size=embedding_dim, window=neighbor_words_num)\n",
    "# Build vocabulary\n",
    "ft_model.build_vocab(sentences=tokenized_corpus)\n",
    "# Train the model\n",
    "ft_model.train(sentences=tokenized_corpus,\n",
    "                total_examples=len(tokenized_corpus),\n",
    "                epochs=100)"
   ]
  },
  {
   "source": [
    "# Exercise III: Transfer learning starting point\n",
    "\n",
    "In this exercise you will see the benefit of using pre-trained vectors as a starting point for your model.\n",
    "\n",
    "You will compare the accuracy of two models trained with two epochs. The architecture of the models is the same: One embedding layer, one LSTM layer with 128 units and the output layer with 5 units which is the number of classes in the sample data. The difference is that one model uses pre-trained vectors on the embedding layer (transfer learning) and the other doesn't.\n",
    "\n",
    "The pre-trained vectors used were the `GloVE` with 200 dimension. The training accuracy history of the validation set of both models are available in the variables `history_no_emb` and `history_emb`.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Import module `matplotlib.pyplot` as `plt`.\n",
    "- Add the list of accuracy from the model without embeddings to the plot.\n",
    "- Add the list of accuracy from the model with embeddings to the plot.\n",
    "- Display the plot using the method `.show()`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plotting package\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Insert lists of accuracy obtained on the validation set\n",
    "plt.plot(history_no_emb['acc'], marker='o')\n",
    "plt.plot(history_emb['acc'], marker='o')\n",
    "\n",
    "# Add extra descriptions to plot\n",
    "plt.title('Learning with and without pre-trained embedding vectors')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['no_embeddings', 'with_embeddings'], loc='upper left')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "<p align='center'>\n",
    "    <img src='image/[2021-02-14 120104].svg'>\n",
    "</p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise IV: Word2Vec\n",
    "\n",
    "In this exercise you will create a Word2Vec model using Keras.\n",
    "\n",
    "The corpus used to pre-train the model is the script of all episodes of the The Big Bang Theory TV show, divided sentence by sentence. It is available in the variable `bigbang`.\n",
    "\n",
    "The text on the corpus was transformed to lower case and all words were tokenized. The result is stored in the `tokenized_corpus` variable.\n",
    "\n",
    "A `Word2Vec` model was pre-trained using a window size of 10 words for context (5 before and 5 after the center word), words with less than 3 occurrences were removed and the skip gram model method was used with 50 dimension. The model is saved on the file `bigbang_word2vec.model`.\n",
    "\n",
    "The class `Word2Vec` is already loaded in the environment from `gensim.models.word2vec`.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Load the pre-trained Word2Vec model.\n",
    "- Store a `list` with the words `\"bazinga\", \"penny\", \"universe\", \"spock\", \"brain\"` in the variable `words_of_interest`, keeping them in that order.\n",
    "- Iterate over each word of interest while using the `.most_similar()` method present on attribute `wv` and append the top 5 similar words to `top5_similar_words` as a dictionary.\n",
    "- Print the found top 5 words for each of the words of interest.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec model\n",
    "w2v_model = Word2Vec.load('bigbang_word2vec.model')\n",
    "\n",
    "# Selected words to check similarities\n",
    "words_of_interest = [\"bazinga\", \"penny\", \"universe\", \"spock\", \"brain\"]\n",
    "\n",
    "# Compute top 5 similar words for each of the words of interest\n",
    "top5_similar_words = []\n",
    "for word in words_of_interest:\n",
    "    top5_similar_words.append(\n",
    "      {word: [item[0] for item in w2v_model.wv.most_similar([word], topn=5)]}\n",
    "    )\n",
    "\n",
    "# Print the similar words\n",
    "print(top5_similar_words)"
   ]
  },
  {
   "source": [
    "# (3) Multi-class classification models\n",
    "\n",
    "## Review of the Sentiment classification model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and compile the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 128))\n",
    "model.add(LSTM(128, dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "source": [
    "## Model architecture\n",
    "Same architecture can be used"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 128))\n",
    "model.add(LSTM(128, dropout=0.2))\n",
    "# Output layer has 'num_classes' units and uses 'softmax'\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "source": [
    "## 20 News Group dataset\n",
    "29 News Groups Dataset\n",
    "\n",
    "- Available on `sklearn.datasets import fetch_20newsgroups`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function to load the data\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# Download train and test sets\n",
    "news_train = fetch_20newsgroups(subset='train')\n",
    "news_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "source": [
    "The data has the following attributes:\n",
    "- `news_train.DESCR`: Documentation.\n",
    "- `news_train.data`: Text data.\n",
    "- `news_train.filenames`: Path to the files on disk.\n",
    "- `news_train.target`: Numerical index of the classes.\n",
    "- `news_train.target_names`: Unique names of the classes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Pre-processing text data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "# Create and fit the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(news_train.data)\n",
    "# Create the (X, Y) variables\n",
    "X_train = tokenizer.texts_to_sequences(news_train.data)\n",
    "X_train = pad_sequences(X_train, maxlen=400)\n",
    "Y_train = to_categorical(news_train.target)"
   ]
  },
  {
   "source": [
    "## Training on data\n",
    "Train the model on training data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, Y_train, batch_size=64, epochs=100)\n",
    "# Evaluate on test data\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "source": [
    "# Exercise V: Exploring 20 News Groups dataset\n",
    "\n",
    "In this exercise, you will be given a sample of the **20 News Groups** dataset obtained using the `fetch_20newsgroups()` function from `sklearn.datasets`, filtering only three classes: `sci.space`, `alt.atheism` and `soc.religion.christian`.\n",
    "\n",
    "The dataset is loaded in the variable `news_dataset`. Its attributes are printed so you can explore them on the console.\n",
    "\n",
    "Fore more details on how to use this function, see the [Sklearn documentation](https://scikit-learn.org/stable/datasets/index.html#the-20-newsgroups-text-dataset).\n",
    "\n",
    "You will tokenize the texts and one-hot encode the labels step by step to understand how the transformations happen.\n",
    "\n",
    "### Instructions 1/4\n",
    "\n",
    "- Print the example article with index `5` from `news_dataset.data`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See example article\n",
    "print(news_dataset.data[5])"
   ]
  },
  {
   "source": [
    "### Instructions 2/4\n",
    "\n",
    "- Transform the data into a sequence of numerical indexes."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See example article\n",
    "print(news_dataset.data[5])\n",
    "\n",
    "# Transform the text into numerical indexes\n",
    "news_num_indices = tokenizer.texts_to_sequences(news_dataset.data)"
   ]
  },
  {
   "source": [
    "### Instructions 3/4\n",
    "\n",
    "- Print the transformed example (index `5`) article."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See example article\n",
    "print(news_dataset.data[5])\n",
    "\n",
    "# Transform the text into numerical indexes\n",
    "news_num_indices = tokenizer.texts_to_sequences(news_dataset.data)\n",
    "\n",
    "# Print the transformed example article\n",
    "print(news_num_indices[5])"
   ]
  },
  {
   "source": [
    "### Instructions 4/4\n",
    "\n",
    "- Transform the labels into one-hot vectors using the function `to_categorical()` and print the original text label and the transformed one-hot vector at index `5` to see the transformed example."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See example article\n",
    "print(news_dataset.data[5])\n",
    "\n",
    "# Transform the text into numerical indexes\n",
    "news_num_indices = tokenizer.texts_to_sequences(news_dataset.data)\n",
    "\n",
    "# Print the transformed example article\n",
    "print(news_num_indices[5])\n",
    "\n",
    "# Transform the labels into one-hot encoded vectors\n",
    "labels_onehot = to_categorical(news_dataset.target)\n",
    "\n",
    "# Check before and after for the sample article\n",
    "print(\"Before: {0}\\nAfter: {1}\".format(news_dataset.target[5], labels_onehot[5]))"
   ]
  },
  {
   "source": [
    "# Exercise VI: Classifying news articles\n",
    "\n",
    "In this exercise you will create a multi-class classification model.\n",
    "\n",
    "The dataset is already loaded in the environment as `news_novel`. Also, all the pre-processing of the training data is already done and `tokenizer` is also available in the environment.\n",
    "\n",
    "A RNN model was pre-trained with the following architecture: use the `Embedding` layer, one `LSTM` layer and the output `Dense` layer expecting three classes: `sci.space`, `alt.atheism`, and `soc.religion.christian`. The weights of this trained model are available on the `classify_news_weights.h5` file.\n",
    "\n",
    "You will pre-process the novel data and evaluate on a new dataset `news_novel`.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Transform the data present on `news_novel.data` using the loaded `tokenizer`.\n",
    "- Pad the obtained sequences of numerical indexes.\n",
    "- Transform the labels present on `news_novel.target` into a one-hot representation.\n",
    "- Evaluate the model using the method `.evaluate()` and print the loss and accuracy obtained.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change text for numerical ids and pad\n",
    "X_novel = tokenizer.texts_to_sequences(news_novel.data)\n",
    "X_novel = pad_sequences(X_novel, maxlen=400)\n",
    "\n",
    "# One-hot encode the labels\n",
    "Y_novel = to_categorical(news_novel.target)\n",
    "\n",
    "# Load the model pre-trained weights\n",
    "model.load_weights('classify_news_weights.h5')\n",
    "\n",
    "# Evaluate the model on the new dataset\n",
    "loss, acc = model.evaluate(X_novel, Y_novel, batch_size=64)\n",
    "\n",
    "# Print the loss and accuracy obtained\n",
    "print(\"Loss:\\t{0}\\nAccuracy:\\t{1}\".format(loss, acc))"
   ]
  },
  {
   "source": [
    "# (4) Assesing the model's performance\n",
    "\n",
    "## Accuracy is not too informative\n",
    "20 classes task with 80% accuracy. Is the model good?\n",
    "- Can it classify all the classes correctly?\n",
    "- Is the accuracy the same for each class?\n",
    "- Is the model ovefitting on the majority class?\n",
    "\n",
    "## Confuse matrix\n",
    "Checking true and predicted for each class\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='image/Screenshot 2021-02-15 160727'>\n",
    "</p>\n",
    "\n",
    "## Precision\n",
    "### Precision\n",
    "$$Precision_{class} = \\frac{Correct_{class}}{Predicted_{class}}$$\n",
    "\n",
    "### In the example:\n",
    "$$Precision_{sci.space} = \\frac{76}{76+7+9} = 0.83$$\n",
    "\n",
    "$$Precision_{alt.atheism} = \\frac{1}{2+1+0} = 0.33$$\n",
    "\n",
    "$$Precision_{soc.religion.christian} = \\frac{3}{0+2+3} = 0.60$$\n",
    "\n",
    "## Recall\n",
    "### Recall\n",
    "$$Recall_{class} = \\frac{Correct_{class}}{N_{class}}$$\n",
    "\n",
    "### In the example:\n",
    "$$Recall_{sci.space} = \\frac{76}{76+2+0} = 0.97$$\n",
    "\n",
    "$$Recall_{alt.atheism} = \\frac{1}{7+1+2} = 0.10$$\n",
    "\n",
    "$$Recall_{soc.religion.christian} = \\frac{3}{9+0+3} = 0.25$$\n",
    "\n",
    "## F1-Score\n",
    "### F1-Score\n",
    "$${f1score} = 2*\\frac{precision_{class} * recall_{class}}{precision_{class} + recall_{class}}$$\n",
    "\n",
    "$${f1score}_{sci.space} = 2*\\frac{0.83 * 0.97}{0.83 + 0.97} = 0.89$$\n",
    "\n",
    "$${f1score}_{alt.atheism} = 2*\\frac{0.33 * 0.10}{0.33 + 0.10} = 0.15$$\n",
    "\n",
    "$${f1score}_{soc.religion.christian} = 2*\\frac{0.60 * 0.25}{0.60 + 0.25} = 0.35$$\n",
    "\n",
    "## Sklearn confusion matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Build the confusion matrix\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "source": [
    "## Performance\n",
    "**Metrics from sklearn**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function of sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "source": [
    "## Performance metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "source": [
    "Add `average=None` to precision, recall and f1 score functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision(y_true, y_pred, average=None))\n",
    "print(recall_score(y_true, y_pred, average=None))\n",
    "print(f1_score(y_true, y_pred, average=None))"
   ]
  },
  {
   "source": [
    "## Classification report\n",
    "One function measure all:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_names = ['sci.space', 'alt.atheism', 'soc.religion.christian']\n",
    "print(classification_report(y_true, y_pred, target_names=lab_names))"
   ]
  },
  {
   "source": [
    "# Exercise VII: Precision-Recall trade-off\n",
    "\n",
    "When working with classification tasks, the term Precision-Recall trade-off often appears. Where does it comes from?\n",
    "\n",
    "Usually, the class with higher probability (obtained by the `.predict_proba()` method) is chosen to assign the document to. But, what if the maximum probability is equal to `0.1`? Should you consider that document to belong to this class with only 10% probability?\n",
    "\n",
    "The answer varies according to problem at hand. It is possible to add a minimum threshold to accept the classification, and by changing the threshold the values of precision and recall move in opposite directions.\n",
    "\n",
    "The variables `y_true` and the model `model` are loaded. Also, if the probability is lower than the threshold, the document will be assigned to `DEFAULT_CLASS` (chosen to be class `2`).\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Use the `.predict_proba()` method to get the probabilities for each class and store them in the `pred_probabilities` variable.\n",
    "- Accept the maximum probability only if it is greater than or equal to `0.5` and store the results in the `y_pred_50` variable.\n",
    "- Use the `np.argmax()` and `np.max()` functions to do the same for a threshold equal to `0.8`.\n",
    "- Print the `trade_off` variable with all the metrics.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get probabilities for each class\n",
    "pred_probabilities = model.predict_proba(X_test)\n",
    "\n",
    "# Thresholds at 0.5 and 0.8\n",
    "y_pred_50 = [np.argmax(x) if np.max(x) >= 0.5 else DEFAULT_CLASS for x in pred_probabilities]\n",
    "y_pred_80 = [np.argmax(x) if np.max(x) >= 0.8 else DEFAULT_CLASS for x in pred_probabilities]\n",
    "\n",
    "trade_off = pd.DataFrame({\n",
    "    'Precision_50': precision_score(y_true, y_pred_50, average=None), \n",
    "    'Precision_80': precision_score(y_true, y_pred_80, average=None), \n",
    "    'Recall_50': recall_score(y_true, y_pred_50, average=None), \n",
    "    'Recall_80': recall_score(y_true, y_pred_80, average=None)}, \n",
    "  index=['Class 1', 'Class 2', 'Class 3'])\n",
    "\n",
    "print(trade_off)"
   ]
  },
  {
   "source": [
    "# Exercise VIII: Precision or Recall, that is the question\n",
    "\n",
    "You learned about a few performance metrics and maybe you are asking, when should I use precision and when should I use recall? Those two metrics are calculated for each class, and sometimes it is difficult to understand when to focus on one and when to focus on the other.\n",
    "\n",
    "Precision is a metric that measures how well the model is predicting some class, while recall measures how well a class is being classified. If precision is high for one class, you can trust your model when it predicts that class. When recall is high for a class, you can rest assured that that class is well understood by the model.\n",
    "\n",
    "Follow the instruction to see this comparison between precision and recall with an example. The functions `precision_score()` and `recall_score()` are loaded.\n",
    "\n",
    "### Instructions 1/3\n",
    "\n",
    "- Compute the precision of the `sentiment_model` using the `sentiment_y_true` and `sentiment_y_pred` variables and store it in the `prec_sentiment` variable.\n",
    "- Print the obtained value.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the precision of the sentiment model\n",
    "prec_sentiment = precision_score(sentiment_y_true, sentiment_y_pred, average=None)\n",
    "print(prec_sentiment)"
   ]
  },
  {
   "source": [
    "### Instructions 2/3\n",
    "\n",
    "- Compute the recall of the `sentiment_model` using the `sentiment_y_true` and `sentiment_y_pred` variables and store on the `rec_sentiment` variable.\n",
    "- Print the obtained value.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the recall of the sentiment model\n",
    "rec_sentiment = recall_score(sentiment_y_true, sentiment_y_pred, average=None)\n",
    "print(rec_sentiment)"
   ]
  },
  {
   "source": [
    "### Instructions 3/3\n",
    "\n",
    "### Question\n",
    "\n",
    "You are a manager at a bank responsible for social media analysis with the task to reduce the bad image your bank has obtained recently because **the organization was not identifying its customers' complaints and needs**. You implemented a sentiment analysis model to classify tweets mentioning the bank's name into good (compliments) or bad (complaints).\n",
    "\n",
    "Imagine the results from the previous steps are the precision and recall measures of the class **complaints** (check the second item on the precision and recall arrays), which of the following is correct:\n",
    "\n",
    "(Don't forget that you can use the console to check the values obtained before.)\n",
    "\n",
    "### Possible Answers\n",
    "\n",
    "- The model is able to correctly classify 75% of the complaint tweets.\n",
    "- The model has 20% error when classifying compliments. (T)\n",
    "- You want a higher recall score to identify most of the customers' complaints instead of a higher precision so you can rely on what the model predicted.\n",
    "- You need to check the accuracy score in order to analyze the complaints of the customers."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise IX: Performance on multi-class classification\n",
    "\n",
    "In this exercise, you will compute the performance metrics for models using the module `sklearn.metrics`.\n",
    "\n",
    "The model is already trained and stored in the variable `model`. Also, the variables `X_test` and `y_true` are also loaded, together with the functions `confusion_matrix()` and `classification_report()` from `sklearn.metrics package`.\n",
    "\n",
    "You will first compute the confusion matrix of the model. Then, to summarize a model's performance, you will compute the precision, recall and F1-score using the `classification_report()` function. In this function, you can optionally pass a `list` containing the classes names (they are stored it in the `news_cat` variable) to the parameter `target_names` to make the report more readable.\n",
    "\n",
    "### Instructions 1/3\n",
    "\n",
    "- Make the predictions on the `X_test` and store it in `predicted`.\n",
    "- Get the class predicted with the higher probability using `np.argmax(axis=1)` and stored it in `y_pred`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict on new data\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Choose the class with higher probability \n",
    "y_pred = np.argmax(predicted, axis=1)"
   ]
  },
  {
   "source": [
    "### Instructions 2/3\n",
    "\n",
    "- Compute the confusion matrix using the function `confusion_matrix()`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict on new data\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Choose the class with higher probability \n",
    "y_pred = np.argmax(predicted, axis=1)\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to predict on new data\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Choose the class with higher probability \n",
    "y_pred = np.argmax(predicted, axis=1)\n",
    "\n",
    "# Compute and print the confusion matrix\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Create the performance report\n",
    "print(classification_report(y_true, y_pred, target_names=news_cat))"
   ]
  }
 ]
}