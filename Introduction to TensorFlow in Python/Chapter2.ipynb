{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Linear models\n",
    "\n",
    "In this chapter, you will learn how to build, solve, and make predictions with models in TensorFlow 2. You will focus on a simple class of models – the linear regression model – and will try to predict housing prices. By the end of the chapter, you will know how to load and manipulate data, construct loss functions, perform minimization, make predictions, and reduce resource use with batch training."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# (1) Input data\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-23 180358.png\">\n",
    "\n",
    "## Importing data for use in TensorFlow\n",
    "\n",
    "- **Data can be imported using Tensorflow**\n",
    "    - Useful for managing compex pipelines\n",
    "    - Not necessary for this chapter\n",
    "- **Simpler option used in this chapter**\n",
    "    - Import data using `pandas`\n",
    "    - Convert data to `numpy\n",
    "    - Use in `tensorflow` without modification\n",
    "\n",
    "How to import and convert data\n",
    "\n",
    "```\n",
    "# Import numpy and pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load data from csv\n",
    "housing = pd.read_csv('kc_housing.csv')\n",
    "\n",
    "# Convert to numpy array\n",
    "housing = np.array(housing)\n",
    "```\n",
    "\n",
    "- We will foucs on data stored in csv format in this chapter\n",
    "- Pandas also has methods for handing data in others formats\n",
    "    - E.g. `read_json`, `read_html`, read_excel`\n",
    "\n",
    "## Parameter of read_csv()\n",
    "\n",
    "| **Parameter** | **Description** | **Default**|\n",
    "| :- | :- | :- |\n",
    "| `filepath_or_buffer` | Accepts a file path or a URL. | `None` |\n",
    "| `sep` | Delimiter between colums | `,` |\n",
    "| `delim_whitespace` | Boolean for whether to delimit whitespace. | `False` |\n",
    "| `encoding` | Specifies encoding to be used if any. | `None` |\n",
    "\n",
    "## Using mixed type datasets\n",
    "\n",
    "<img src='image/Screenshot 2021-01-23 181841.png'>\n",
    "\n",
    "## Setting the data type\n",
    "\n",
    "```\n",
    "# Load KC dataset\n",
    "housing = pd.read_csv('kc_housing.csv')\n",
    "\n",
    "# Convert price column to float32\n",
    "price = np.array(housing['prince'], np.float32)\n",
    "\n",
    "# Convert waterfront column to Boolean\n",
    "waterfront = np.array(housing['waterfront'], np.bool)\n",
    "```\n",
    "\n",
    "### Or\n",
    "\n",
    "```\n",
    "# Load KC dataset\n",
    "housing = pd.read_csv('kc_housing.csv')\n",
    "\n",
    "# Convert price column to float32\n",
    "price = tf.cast(housing['price'], tf.float32)\n",
    "\n",
    "# Convert waterfront column to Boolean\n",
    "waterfront = tf.cast(housing['waterfront'], tf.bool)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise I: Load data using pandas\n",
    "\n",
    "Before you can train a machine learning model, you must first import data. There are several valid ways to do this, but for now, we will use a simple one-liner from `pandas`: `pd.read_csv()`. Recall from the video that the first argument specifies the path or URL. All other arguments are optional.\n",
    "\n",
    "In this exercise, you will import the King County housing dataset, which we will use to train a linear model later in the chapter.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Import `pandas` under the alias pd.\n",
    "- Assign the path to a string variable with the name `data_path`.\n",
    "- Load the dataset as a pandas dataframe named `housing`.\n",
    "- Print the `price` column of `housing`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas under the alias pd\n",
    "import pandas as pd\n",
    "\n",
    "# Assign the path to a string variable named data_path\n",
    "data_path = 'kc_house_data.csv'\n",
    "\n",
    "# Load the dataset as a dataframe named housing\n",
    "housing = pd.read_csv(data_path)\n",
    "\n",
    "# Print the price column of housing\n",
    "print(housing['price'])"
   ]
  },
  {
   "source": [
    "# Exercise II: Setting the data type\n",
    "\n",
    "In this exercise, you will both load data and set its type. Note that `housing` is available and `pandas` has been imported as `pd`. You will import `numpy` and `tensorflow`, and define tensors that are usable in `tensorflow` using columns in `housing` with a given data type. Recall that you can select the `price` column, for instance, from `housing` using `housing['price']`.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Import `numpy` and `tensorflow` under their standard aliases.\n",
    "- Use a `numpy` array to set the tensor `price` to have a data type of 32-bit floating point number\n",
    "- Use the `tensorflow` function `cast()` to set the tensor `waterfront` to have a Boolean data type.\n",
    "- Print `price` and then `waterfront`. Did you notice any important differences?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and tensorflow with their standard aliases\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Use a numpy array to define price as a 32-bit float\n",
    "price = np.array(housing['price'], np.float32)\n",
    "\n",
    "# Define waterfront as a Boolean using cast\n",
    "waterfront = tf.cast(housing['waterfront'], tf.bool)\n",
    "\n",
    "# Print price and waterfront\n",
    "print(price)\n",
    "print(waterfront)"
   ]
  },
  {
   "source": [
    "# (2) Loss function\n",
    "\n",
    "## Introduction to loss function\n",
    "- **Fundamental `tensorflow` operation**\n",
    "    - Used to train a model\n",
    "    - Measuring of model fit\n",
    "- **Higher value -> worse fit**\n",
    "    - Minimize the loss function\n",
    "\n",
    "## Common loss functions in TensorFlow\n",
    "- **TensorFlow has operations for common loss function**\n",
    "    - Mean square error (MSE)\n",
    "    - Mean absolute error (MAE)\n",
    "- **Loss function are accessible from `tf.keras.losses()`**\n",
    "\n",
    "## Why do we care about loss function\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-24 013740.png\">\n",
    "\n",
    "- **MSE**\n",
    "    - Strongly penalizes outliers\n",
    "    - High (gradient) sensitivity\n",
    "- **MAE**\n",
    "    - Scales linearly with size of error\n",
    "    - Low sensitivity near minimam\n",
    "- **Huber**\n",
    "    - Similar to MSE near Minimize\n",
    "    - Similar to MAE away from minimize\n",
    "\n",
    "## Defining a loss function\n",
    "\n",
    "```\n",
    "# Import TensorFlow under standard alias\n",
    "import tensorflow as tf\n",
    "\n",
    "# Computer the MSE loss\n",
    "loss = tf.keras.loss.mse(target, predictions)\n",
    "```\n",
    "\n",
    "```\n",
    "# Define a linear regression\n",
    "def linear_regression(intercept, slope=slope, features=features):\n",
    "    return intercept + features*slope\n",
    "```\n",
    "\n",
    "```\n",
    "# Define a loss function to compute the MSE\n",
    "def loss_function(intercept, slope, targets=targets, features=features):\n",
    "    # Compute the predictions for a linear model\n",
    "    predictions = linear_regression(intercept, slope)\n",
    "\n",
    "    # Return the loss\n",
    "    return tf.leras.losses.mse(targets, predictions)\n",
    "```\n",
    "\n",
    "```\n",
    "# Compute the loss for test data inputs\n",
    "loss function(intercept, slope, test_targets, test_features)\n",
    "```\n",
    "\n",
    "```\n",
    "# Compute the loss for default data input\n",
    "loss_function(intercept, slope)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise III: Loss functions in TensorFlow\n",
    "\n",
    "In this exercise, you will compute the loss using data from the King County housing dataset. You are given a target, `price`, which is a tensor of house prices, and `predictions`, which is a tensor of predicted house prices. You will evaluate the loss function and print out the value of the loss.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Import the `keras` module from tensorflow. Then, use `price` and `predictions` to compute the mean squared error (mse).\n",
    "- Modify your code to compute the mean absolute error (mae), rather than the mean squared error (mse)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the keras module from tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "# Compute the mean absolute error (mae)\n",
    "loss = keras.losses.mae(price, predictions)\n",
    "\n",
    "# Print the mean absolute error (mae)\n",
    "print(loss.numpy())"
   ]
  },
  {
   "source": [
    "# Exercise IV: Modifying the loss function\n",
    "\n",
    "In the previous exercise, you defined a `tensorflow` loss function and then evaluated it once for a set of actual and predicted values. In this exercise, you will compute the loss within another function called `loss_function()`, which first generates predicted values from the data and variables. The purpose of this is to construct a function of the trainable model variables that returns the loss. You can then repeatedly evaluate this function for different variable values until you find the minimum. In practice, you will pass this function to an optimizer in `tensorflow`. Note that `features` and targets have been defined and are available. Additionally, `Variable`, `float32`, and `keras` are available.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "\n",
    "- Define a variable, `scalar`, with an initial value of 1.0 and a type of `float32`.\n",
    "- Define a function called `loss_function()`, which takes `scalar`, `features`, and `targets` as arguments in that order.\n",
    "- Use a mean absolute error loss function.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Initialize a variable named scalar\n",
    "scalar = Variable(1.0, float32)\n",
    "\n",
    "# Define the model\n",
    "def model(scalar, features = features):\n",
    "  \treturn scalar * features\n",
    "\n",
    "# Define a loss function\n",
    "def loss_function(scalar, features = features, targets = targets):\n",
    "\t# Compute the predicted values\n",
    "\tpredictions = model(scalar, features)\n",
    "    \n",
    "\t# Return the mean absolute error loss\n",
    "\treturn keras.losses.mae(targets, predictions)\n",
    "\n",
    "# Evaluate the loss function and print the loss\n",
    "print(loss_function(scalar).numpy())"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# (3) Linear regression\n",
    "\n",
    "## What is a linear regression?\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-24 015537.png\">\n",
    "\n",
    "## The Linear regrssion model\n",
    "\n",
    "- **A linaer regression model assumes a linear relationship**:\n",
    "    - $price = intercept + size*slop + error$\n",
    "- **This is an example of a univariate regression**\n",
    "    - There is only feature, `size`\n",
    "- **Multiplt regression models have more than one feature**\n",
    "    - E.g. `size` and `location`\n",
    "\n",
    "## Linear regression in TensorFlow\n",
    "\n",
    "```\n",
    "# Define the targets and features\n",
    "price = np.array(housing['price'], np.float32)\n",
    "size = np.array(housing['sqft_living', np.float32])\n",
    "\n",
    "# Define the intercept and slope\n",
    "intercept = tf.Variable(0.1, np.float32)\n",
    "slope = tf.Variable(0.1, np.float32)\n",
    "```\n",
    "\n",
    "```\n",
    "# Define a linear regression model\n",
    "def linear_regression(intercept, slope, features=size):\n",
    "    return intercept + features*slope\n",
    "```\n",
    "\n",
    "```\n",
    "def loss_function(intercept, slope, targets=price, feature=size):\n",
    "    predictions = linear_regression(intercept, slope)\n",
    "    return tf.keras.losses.mse(targets, predictions)\n",
    "```\n",
    "\n",
    "## Linear regression in TensorFlow\n",
    "\n",
    "```\n",
    "# Define an optimization operation\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "```\n",
    "\n",
    "```\n",
    "# Minizmize the loss function and print the loss\n",
    "for j in range(1000):\n",
    "    opt.minizmize(lamda: loss_function(intercept, slope),\\\n",
    "    var_list=[intercept, slope])\n",
    "    print(loss_function(intercept, slope))\n",
    "```\n",
    "\n",
    "```\n",
    "# Print the trained parameters\n",
    "print(intercept,numpy(), slope.numpy())\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise V: Set up a linear regression\n",
    "\n",
    "A univariate linear regression identifies the relationship between a single feature and the target tensor. In this exercise, we will use a property's lot size and price. Just as we discussed in the video, we will take the natural logarithms of both tensors, which are available as `price_log` and `size_log`.\n",
    "\n",
    "In this exercise, you will define the model and the loss function. You will then evaluate the loss function for two different values of `intercept` and `slope`. Remember that the predicted values are given by `intercept + features*slope`. Additionally, note that `keras.losses.mse()` is available for you. Furthermore, `slope` and `intercept` have been defined as variables.\n",
    "\n",
    "### Instructioss\n",
    "\n",
    "\n",
    "- Define a function that returns the predicted values for a linear regression using `intercept`, `features`, and `slope`, and without using `add()` or `multiply()`.\n",
    "- Complete the `loss_function()` by adding the model's variables, `intercept` and `slope`, as arguments.\n",
    "- Compute the mean squared error using `targets` and `predictions`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a linear regression model\n",
    "def linear_regression(intercept, slope, features = size_log):\n",
    "\treturn intercept + features*slope\n",
    "\n",
    "# Set loss_function() to take the variables as arguments\n",
    "def loss_function(intercept, slope, features = size_log, targets = price_log):\n",
    "\t# Set the predicted values\n",
    "\tpredictions = linear_regression(intercept, slope, features)\n",
    "    \n",
    "    # Return the mean squared error loss\n",
    "\treturn keras.losses.mse(targets, predictions)\n",
    "\n",
    "# Compute the loss for different slope and intercept values\n",
    "print(loss_function(0.1, 0.1).numpy())\n",
    "print(loss_function(0.1, 0.5).numpy())"
   ]
  },
  {
   "source": [
    "# Exercise VI:Train a linear model\n",
    "\n",
    "In this exercise, we will pick up where the previous exercise ended. The intercept and slope, `intercept` and `slope`, have been defined and initialized. Additionally, a function has been defined, `loss_function(intercept, slope)`, which computes the loss using the data and model variables.\n",
    "\n",
    "You will now define an optimization operation as `opt`. You will then train a univariate linear model by minimizing the loss to find the optimal values of `intercept` and `slope`. Note that the `opt` operation will try to move closer to the optimum with each step, but will require many steps to find it. Thus, you must repeatedly execute the operation.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "\n",
    "- Initialize an Adam optimizer as `opt` with a learning rate of 0.5.\n",
    "- Apply the `.minimize()` method to the optimizer.\n",
    "- Pass `loss_function()` with the appropriate arguments as a lambda function to `.minimize()`.\n",
    "- Supply the list of variables that need to be updated to `var_list`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an adam optimizer\n",
    "opt = keras.optimizers.Adam(0.5)\n",
    "\n",
    "for j in range(100):\n",
    "\t# Apply minimize, pass the loss function, and supply the variables\n",
    "\topt.minimize(lambda: loss_function(intercept, slope), var_list=[intercept, slope])\n",
    "\n",
    "\t# Print every 10th value of the loss\n",
    "\tif j % 10 == 0:\n",
    "\t\tprint(loss_function(intercept, slope).numpy())\n",
    "\n",
    "# Plot data and regression line\n",
    "plot_results(intercept, slope)"
   ]
  },
  {
   "source": [
    "# Exercise VII: Multiple linear regression\n",
    "\n",
    "In most cases, performing a univariate linear regression will not yield a model that is useful for making accurate predictions. In this exercise, you will perform a multiple regression, which uses more than one feature.\n",
    "\n",
    "You will use `price_log` as your target and `size_log` and `bedrooms` as your features. Each of these tensors has been defined and is available. You will also switch from using the the mean squared error loss to the mean absolute error loss: `keras.losses.mae()`. Finally, the predicted values are computed as follows: `params[0] + feature1*params[1] + feature2*params[2]`. Note that we've defined a vector of parameters, `params`, as a variable, rather than using three variables. Here, `params[0]` is the intercept and `params[1]` and `params[2]` are the slopes.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Define a linear regression model that returns the predicted values.\n",
    "- Set `loss_function()` to take the parameter vector as an input.\n",
    "- Use the mean absolute error loss.\n",
    "- Complete the minimization operation.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the linear regression model\n",
    "def linear_regression(params, feature1 = size_log, feature2 = bedrooms):\n",
    "\treturn params[0] + feature1*params[1] + feature2*params[2]\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(params, targets = price_log, feature1 = size_log, feature2 = bedrooms):\n",
    "\t# Set the predicted values\n",
    "\tpredictions = linear_regression(params, feature1, feature2)\n",
    "  \n",
    "\t# Use the mean absolute error loss\n",
    "\treturn keras.losses.mae(targets, predictions)\n",
    "\n",
    "# Define the optimize operation\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "# Perform minimization and print trainable variables\n",
    "for j in range(10):\n",
    "\topt.minimize(lambda: loss_function(params), var_list=[params])\n",
    "\tprint_results(params)"
   ]
  },
  {
   "source": [
    "# (4) Batch trianing\n",
    "\n",
    "# What is batch training?\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-24 024858.png\">\n",
    " \n",
    "<img src=\"image/Screenshot 2021-01-24 024938.png\">\n",
    "\n",
    "## The chunksize parameter\n",
    "- `pd.read_csv()` allows us to load data in batches\n",
    "    - Avoid loading entire dataset\n",
    "    - `chunksize` paramter provides batch size\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data in batches\n",
    "for batch in pd.read_csv('kc_housing.csv', chunksize=100):\n",
    "    # Extract price column\n",
    "    price = np.array(batch['price'], np.float32)\n",
    "\n",
    "    # Extract size column\n",
    "    size = np.array(batch['size'], np.float32)\n",
    "```\n",
    "\n",
    "## Training a linear model in batches\n",
    "\n",
    "```\n",
    "# Import tensorflow, pandas, numpy\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "```\n",
    "# Define trainable variables\n",
    "intercept = tf.Variable(0.1, tf.float32)\n",
    "slope = tf.Variable(0.1, tf.float32)\n",
    "```\n",
    "\n",
    "```\n",
    "# Compute predicted values and return loss function\n",
    "def loss_function(intercept, slope, targets, features):\n",
    "    predictions = linear_regression(intercept, slope, features)\n",
    "    return tf.keras.losses.mse(targets, predictions)\n",
    "```\n",
    "\n",
    "```\n",
    "# Define optimization operation\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "```\n",
    "\n",
    "```\n",
    "# Load the data in batches from pandas\n",
    "for batch in pd.read_csv('kv_housing.csv', chunksize=100):\n",
    "    # Extract the target and feature columns\n",
    "    price_batch = np.array(batch['price'], np.float32)\n",
    "    size_batch = np.array(batch['lot_size'], np.float32)\n",
    "\n",
    "    # Minimize the loss function\n",
    "    opt.minimize(lamda: loss_function(intercept, slope, price_batch, var_list=[intercept, slope]))\n",
    "```\n",
    "\n",
    "```\n",
    "# Print parameter values\n",
    "print(intercept.numpy(), slope.numpy())\n",
    "```\n",
    "\n",
    "## Full sample versus batch training\n",
    "\n",
    "- **Full sample**\n",
    "    1. One update per epoch\n",
    "    2. Accepts dataset without modification\n",
    "    3. Limited by memory\n",
    "- ** Batch Training**\n",
    "    1. Multiple updates per epoch\n",
    "    2. Requires division of dataset\n",
    "    3. No limit on dataset size"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise VII: Preparing to batch train\n",
    "\n",
    "Before we can train a linear model in batches, we must first define variables, a loss function, and an optimization operation. In this exercise, we will prepare to train a model that will predict `price_batch`, a batch of house prices, using `size_batch`, a batch of lot sizes in square feet. In contrast to the previous lesson, we will do this by loading batches of data using `pandas`, converting it to `numpy` arrays, and then using it to minimize the loss function in steps.\n",
    "\n",
    "`Variable()`, `keras()`, and `float32` have been imported for you. Note that you should not set default argument values for either the model or loss function, since we will generate the data in batches during the training process.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "\n",
    "- Define `intercept` as having an initial value of 10.0 and a data type of 32-bit float.\n",
    "- Define the model to return the predicted values using `intercept`, `slope`, and `features`.\n",
    "- Define a function called `loss_function()` that takes `intercept`, `slope`, `targets`, and `features` as arguments and in that order. Do not set default argument values.\n",
    "- Define the mean squared error loss function using `targets` and `predictions`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the intercept and slope\n",
    "intercept = Variable(10.0, float32)\n",
    "slope = Variable(0.5, float32)\n",
    "\n",
    "# Define the model\n",
    "def linear_regression(intercept, slope, features):\n",
    "\t# Define the predicted values\n",
    "\treturn intercept + features*slope\n",
    "\n",
    "# Define the loss function\n",
    "def loss_function(intercept, slope, targets, features):\n",
    "\t# Define the predicted values\n",
    "\tpredictions = linear_regression(intercept, slope, features)\n",
    "    \n",
    " \t# Define the MSE loss\n",
    "\treturn keras.losses.mse(targets, predictions)"
   ]
  },
  {
   "source": [
    "# Exercise VIII: Training a linear model in batches\n",
    "\n",
    "In this exercise, we will train a linear regression model in batches, starting where we left off in the previous exercise. We will do this by stepping through the dataset in batches and updating the model's variables, `intercept` and `slope`, after each step. This approach will allow us to train with datasets that are otherwise too large to hold in memory.\n",
    "\n",
    "Note that the loss function,`loss_function(intercept, slope, targets, features)`, has been defined for you. Additionally, `keras` has been imported for you and `numpy` is available as `np`. The trainable variables should be entered into `var_list` in the order in which they appear as loss function arguments.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "\n",
    "- Use the `.Adam()` optimizer.\n",
    "- Load in the data from `'kc_house_data.csv'` in batches with a `chunksize` of 100.\n",
    "- Extract the `price` column from `batch`, convert it to a `numpy` array of type 32-bit float, and assign it to `price_batch`.\n",
    "- Complete the loss function, fill in the list of trainable variables, and perform minimization.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize adam optimizer\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "# Load data in batches\n",
    "for batch in pd.read_csv('kc_house_data.csv', chunksize=100):\n",
    "\tsize_batch = np.array(batch['sqft_lot'], np.float32)\n",
    "\n",
    "\t# Extract the price values for the current batch\n",
    "\tprice_batch = np.array(batch['price'], np.float32)\n",
    "\n",
    "\t# Complete the loss, fill in the variable list, and minimize\n",
    "\topt.minimize(lambda: loss_function(intercept, slope, price_batch, size_batch), var_list=[intercept, slope])\n",
    "\n",
    "# Print trained parameters\n",
    "print(intercept.numpy(), slope.numpy())"
   ]
  }
 ]
}