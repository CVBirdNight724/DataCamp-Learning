{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "\n",
    "The previous chapters taught you how to build models in TensorFlow 2. In this chapter, you will apply those same tools to build, train, and make predictions with neural networks. You will learn how to define dense layers, apply activation functions, select an optimizer, and apply regularization to reduce overfitting. You will take advantage of TensorFlow's flexibility by using both low-level linear algebra and high-level Keras API operations to define and train models."
   ]
  },
  {
   "source": [
    "# (1) Dense layers\n",
    "\n",
    "## The linear regression model\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-24 232039.png\">\n",
    "\n",
    "## What is a nueral network?\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-24 232132.png\">\n",
    "\n",
    "<imge src=\"image/Screenshot 2021-01-24 232213.png\">\n",
    "\n",
    "A dense layer applies weights to all nodes from the previous layer.\n",
    "\n",
    "## A simple dense layer\n",
    "\n",
    "```\n",
    "import tensorflow as tf\n",
    "```\n",
    "\n",
    "```\n",
    "# Define inputs (features)\n",
    "inputs = tf.constants([[1, 35]])\n",
    "```\n",
    "\n",
    "```\n",
    "# Define weights\n",
    "weights = tf.Variable([[-0.05], [-0.01]])\n",
    "```\n",
    "\n",
    "```\n",
    "# Define the bias\n",
    "bias = tf.Variable([0.5])\n",
    "```\n",
    "\n",
    "```\n",
    "# Multiply input (features) by the weights\n",
    "product = tf.matmul(inputs, weights)\n",
    "```\n",
    "\n",
    "```\n",
    "# Define dense layer\n",
    "dense = tf.keras.activations.sigmoid(product+bias)\n",
    "```\n",
    "<img src=\"image/Screenshot 2021-01-24 232706.png\">\n",
    "\n",
    "## Defining a complete model\n",
    "\n",
    "```\n",
    "import tensorflow as tf\n",
    "```\n",
    "\n",
    "```\n",
    "# Define input (features) layer\n",
    "inputs = tf.constant(data, tf.float32)\n",
    "```\n",
    "\n",
    "```\n",
    "# Define first dense layer\n",
    "dense1 = tf.keras.layers.Dense(10, activation='sigmod')(input)\n",
    "```\n",
    "\n",
    "```\n",
    "# Define second dense layer\n",
    "dense2 = tf.keras.layers.Dense(5, activation='sigmod')(dense1)\n",
    "```\n",
    "\n",
    "```\n",
    "# Define output (predictions) layer\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "```\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-24 233110.png\">\n",
    "\n",
    "## High-level versus low-level approach\n",
    "\n",
    "- **High-level approach**\n",
    "    - High-level API operations\n",
    "\n",
    "```\n",
    "dense = keras.layers.Dense(10, activation='sigmoid')\n",
    "```\n",
    "\n",
    "- **Low-level approach**\n",
    "    - Linear-algebraic operations\n",
    "\n",
    "```\n",
    "prod = matmul(inputs, weights)\n",
    "dense = keras.activations.sigmoid(prod)\n",
    "```\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise I: The linear algebra of dense layers\n",
    "\n",
    "There are two ways to define a dense layer in `tensorflow`. The first involves the use of low-level, linear algebraic operations. The second makes use of high-level `keras` operations. In this exercise, we will use the first method to construct the network shown in the image below.\n",
    "\n",
    "<img src=\"image/3_2_1_network2.png\">\n",
    "\n",
    "The input layer contains 3 features -- education, marital status, and age -- which are available as `borrower_features`. The hidden layer contains 2 nodes and the output layer contains a single node.\n",
    "\n",
    "For each layer, you will take the previous layer as an input, initialize a set of weights, compute the product of the inputs and weights, and then apply an activation function. Note that `Variable()`, `ones()`, `matmul()`, and `keras()` have been imported from `tensorflow`.\n",
    "\n",
    "### Instructions \n",
    "\n",
    "- Initialize `weights1` as a variable using a 3x2 tensor of ones.\n",
    "- Compute the product of `borrower_features` by `weights1` using matrix multiplication.\n",
    "- Use a sigmoid activation function to transform `product1 + bias1`.\n",
    "\n",
    "- Initialize `weights2` as a variable using a 2x1 tensor of ones.\n",
    "- Compute the product of `dense1` by `weights2` using matrix multiplication.\n",
    "- Use a sigmoid activation function to transform `product2 + bias2`.\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous step\n",
    "bias1 = Variable(1.0)\n",
    "weights1 = Variable(ones((3, 2)))\n",
    "product1 = matmul(borrower_features, weights1)\n",
    "dense1 = keras.activations.sigmoid(product1 + bias1)\n",
    "\n",
    "# Initialize bias2 and weights2\n",
    "bias2 = Variable(1.0)\n",
    "weights2 = Variable(ones((2, 1)))\n",
    "\n",
    "# Perform matrix multiplication of dense1 and weights2\n",
    "product2 = matmul(dense1, weights2)\n",
    "\n",
    "# Apply activation to product2 + bias2 and print the prediction\n",
    "prediction = keras.activations.sigmoid(product2 + bias2)\n",
    "print('\\n prediction: {}'.format(prediction.numpy()[0,0]))\n",
    "print('\\n actual: 1')"
   ]
  },
  {
   "source": [
    "# Exercise II: The low-level approach with multiple examples\n",
    "\n",
    "In this exercise, we'll build further intuition for the low-level approach by constructing the first dense hidden layer for the case where we have multiple examples. We'll assume the model is trained and the first layer weights, `weights1`, and bias, `bias1`, are available. We'll then perform matrix multiplication of the `borrower_features` tensor by the `weights1` variable. Recall that the `borrower_features` tensor includes education, marital status, and age. Finally, we'll apply the sigmoid function to the elements of `products1 + bias1`, yielding `dense1`.\n",
    "\n",
    "$products1 = \\begin{bmatrix} 3 & 3 & 23 \\\\ 2 & 1 & 24 \\\\ 1 & 1 & 49 \\\\ 1 & 1 & 49 \\\\ 2 & 1 & 49\\end{bmatrix}\\begin{bmatrix} -0.6 & 0.6 \\\\ 0.8 & -0.3 \\\\ -0.09 & -0.08\\end{bmatrix}$  \n",
    "\n",
    "Note that `matmul()` and `keras()` have been imported from `tensorflow`.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "\n",
    "- Compute `products1` by matrix multiplying the features tensor by the weights.\n",
    "- Use a sigmoid activation function to transform `products1 + bias1`.\n",
    "- Print the shapes of `borrower_features`, `weights1`, `bias1`, and `dense1`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the product of borrower_features and weights1\n",
    "products1 = matmul(borrower_features, weights1)\n",
    "\n",
    "# Apply a sigmoid activation function to products1 + bias1\n",
    "dense1 = keras.activations.sigmoid(products1 + bias1)\n",
    "\n",
    "# Print the shapes of borrower_features, weights1, bias1, and dense1\n",
    "print('\\n shape of borrower_features: ', borrower_features.shape)\n",
    "print('\\n shape of weights1: ', weights1.shape)\n",
    "print('\\n shape of bias1: ', bias1.shape)\n",
    "print('\\n shape of dense1: ', dense1.shape)"
   ]
  },
  {
   "source": [
    "# Exercise III: Using the dense layer operation\n",
    "\n",
    "We've now seen how to define dense layers in `tensorflow` using linear algebra. In this exercise, we'll skip the linear algebra and let `keras` work out the details. This will allow us to construct the network below, which has 2 hidden layers and 10 features, using less code than we needed for the network with 1 hidden layer and 3 features.\n",
    "\n",
    "<img src=\"image/10_7_3_1_network.png\">\n",
    "\n",
    "To construct this network, we'll need to define three dense layers, each of which takes the previous layer as an input, multiplies it by weights, and applies an activation function. Note that input data has been defined and is available as a 100x10 tensor: `borrower_features`. Additionally, the `keras.layers` module is available.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "\n",
    "- Set `dense1` to be a dense layer with 7 output nodes and a sigmoid activation function.\n",
    "- Define `dense2` to be dense layer with 3 output nodes and a sigmoid activation function.\n",
    "- Define `predictions` to be a dense layer with 1 output node and a sigmoid activation function.\n",
    "- Print the shapes of `dense1`, `dense2`, and `predictions` in that order using the `.shape` method. Why does each of these tensors have 100 rows?\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the first dense layer\n",
    "dense1 = keras.layers.Dense(7, activation='sigmoid')(borrower_features)\n",
    "\n",
    "# Define a dense layer with 3 output nodes\n",
    "dense2 = keras.layers.Dense(3, activation='sigmoid')(dense1)\n",
    "\n",
    "# Define a dense layer with 1 output node\n",
    "predictions = keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "# Print the shapes of dense1, dense2, and predictions\n",
    "print('\\n shape of dense1: ', dense1.shape)\n",
    "print('\\n shape of dense2: ', dense2.shape)\n",
    "print('\\n shape of predictions: ', predictions.shape)"
   ]
  }
 ]
}