{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "#  Clustering for dataset exploration\n",
    "\n",
    "Learn how to discover the underlying groups (or \"clusters\") in a dataset. By the end of this chapter, you'll be clustering companies using their stock market prices, and distinguishing different species by clustering their measurements. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# (1) Unsupervised Learning\n",
    "\n",
    "## Unsupervised Learning\n",
    "- Unsupervised learning finds patterns in data\n",
    "- E.g., clustering customers by their purchaces\n",
    "- Compressigng the data using purchaces patterns (dimension reduction)\n",
    "\n",
    "## Supervised vs unsupervised learning\n",
    "- Supervised learning finds patterns for a prediction task\n",
    "- E.g., classify tumors as benign or cancerous (labels)\n",
    "- Unsupervised learning finds patterns in data\n",
    "- ... but without a specific prediction task in mind\n",
    "\n",
    "## Iris dataset\n",
    "- Measurements of many iris plants\n",
    "- Three species of iris:\n",
    "    - setosa\n",
    "    - versicolor\n",
    "    - virginica\n",
    "- Petal length, petal width, sepal length (the features of the dataset)\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='image/Screenshot 2021-02-18 000035.png'>\n",
    "</p>\n",
    "\n",
    "## Arrays, features & samples\n",
    "- 2D NumPy array\n",
    "- Columns are measurements (the features)\n",
    "- Rows represent iris plants (the samples)\n",
    "\n",
    "## Iris data is 4-dimensional\n",
    "- Iris samples are points in 4 dimensional space\n",
    "- Dimension = number of features\n",
    "- Dimension too high to visualize!\n",
    "- ... but un supervised learning gives insight\n",
    "\n",
    "## k-means clustering\n",
    "- Find clusters of samples\n",
    "- Number of clusters must be spescified\n",
    "- Implemented in `sklearn` (\"scikit-learn\")"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model.predict(samples)"
   ]
  },
  {
   "source": [
    "## Cluster labels for new samples\n",
    "- New samples can be assigned to existing clusters\n",
    "- k-means remembers the mean of each cluster (the \"centroids\")\n",
    "- Finds the nearest centroid to each new sample"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = model.predict(new_samples)\n",
    "print(new_labels)  "
   ]
  },
  {
   "source": [
    "## Scatter plots\n",
    "- Scatter plot of sepal length vs. petal length\n",
    "- Each point represents an iris sample\n",
    "- Color points by cluster labels\n",
    "- PyPlot (`matplotlib.pyplot`)\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='image/Screenshot 2021-02-18 010119.png'>\n",
    "</p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matploylib.pyplot as plt\n",
    "xs = samples[:, 0]\n",
    "ys = samples[:, 2]\n",
    "plt.scatter(xs, ys, c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "# Exercise I: How many clusters?\n",
    "\n",
    "You are given an array `points` of size 300x2, where each row gives the (x, y) co-ordinates of a point on a map. Make a scatter plot of these points, and use the scatter plot to guess how many clusters there are.\n",
    "\n",
    "`matplotlib.pyplot` has already been imported as `plt`. In the IPython Shell:\n",
    "\n",
    "    Create an array called `xs` that contains the values of `points[:,0]` - that is, column `0` of `points`.\n",
    "    Create an array called `ys` that contains the values of `points[:,1]` - that is, column `1` of `points`.\n",
    "    Make a scatter plot by passing `xs` and `ys` to the `plt.scatter()` function.\n",
    "    Call the `plt.show()` function to show your plot.\n",
    "\n",
    "How many clusters do you see?\n",
    "\n",
    "### Instructions\n",
    "#### Possible Answers\n",
    "- 2\n",
    "- 3 (T)\n",
    "- 300"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise II: Clustering 2D points\n",
    "\n",
    "From the scatter plot of the previous exercise, you saw that the points seem to separate into 3 clusters. You'll now create a KMeans model to find 3 clusters, and fit it to the data points from the previous exercise. After the model has been fit, you'll obtain the cluster labels for some new points using the `.predict()` method.\n",
    "\n",
    "You are given the array `points` from the previous exercise, and also an array `new_points`.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Import `KMeans` from `sklearn.cluster`.\n",
    "- Using `KMeans()`, create a `KMeans` instance called `model` to find `3` clusters. To specify the number of clusters, use the `n_clusters` keyword argument.\n",
    "- Use the `.fit()` method of `model` to fit the model to the array of points `points`.\n",
    "- Use the `.predict()` method of `model` to predict the cluster labels of `new_points`, assigning the result to `labels`.\n",
    "- Hit 'Submit Answer' to see the cluster labels of `new_points`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create a KMeans instance with 3 clusters: model\n",
    "model = KMeans(n_clusters=3)\n",
    "\n",
    "# Fit model to points\n",
    "model.fit(points)\n",
    "\n",
    "# Determine the cluster labels of new_points: labels\n",
    "labels = model.predict(new_points)\n",
    "\n",
    "# Print cluster labels of new_points\n",
    "print(labels)\n"
   ]
  },
  {
   "source": [
    "# Exercise III: Inspect your clustering\n",
    "\n",
    "Let's now inspect the clustering you performed in the previous exercise!\n",
    "\n",
    "A solution to the previous exercise has already run, so `new_points` is an array of points and `labels` is the array of their cluster labels.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Import `matplotlib.pyplot` as `plt`.\n",
    "- Assign column `0` of `new_points` to `xs`, and column `1` of `new_points` to `ys`.\n",
    "- Make a scatter plot of `xs` and `ys`, specifying the `c=labels` keyword arguments to color the points by their cluster label. Also specify `alpha=0.5`.\n",
    "- Compute the coordinates of the centroids using the `.cluster_centers_` attribute of `model`.\n",
    "- Assign column `0` of `centroids` to `centroids_x`, and column `1` of `centroids` to `centroids_y`.\n",
    "- Make a scatter plot of `centroids_x` and `centroids_y`, using `'D'` (a diamond) as a `marker` by specifying the marker parameter. Set the size of the markers to be `50` using `s=50`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assign the columns of new_points: xs and ys\n",
    "xs = new_points[:,0]\n",
    "ys = new_points[:,1]\n",
    "\n",
    "# Make a scatter plot of xs and ys, using labels to define the colors\n",
    "plt.scatter(xs, ys, c=labels, alpha=0.5)\n",
    "\n",
    "# Assign the cluster centers: centroids\n",
    "centroids = model.cluster_centers_\n",
    "\n",
    "# Assign the columns of centroids: centroids_x, centroids_y\n",
    "centroids_x = centroids[:,0]\n",
    "centroids_y = centroids[:,1]\n",
    "\n",
    "# Make a scatter plot of centroids_x and centroids_y\n",
    "plt.scatter(centroids_x, centroids_y, marker='D', s=50)\n",
    "plt.show()\n"
   ]
  },
  {
   "source": [
    "## Plot\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='image/[2021-02-18] 012831.svg' width=30%>\n",
    "</p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# (2) Evaluation a clustering\n",
    "\n",
    "## Evaluation a clustering\n",
    "- Can check correspondence with e.g. iris species\n",
    "- ... but what if there are no species to check against?\n",
    "- Measure quality of a clustering\n",
    "- Informs choice of how many clusters to look for\n",
    "\n",
    "## Iris: Clusters vs species\n",
    "- k-means found 3 clusters amongst the iris samples\n",
    "- Do the clusters correspond to the species?\n",
    "\n",
    "| species (label) | setosa | versicolor | virginica |\n",
    "| :-: | :-: | :-: | :-:|\n",
    "| 0 | 0 | 2 | 36 |\n",
    "| 1 | 50 | 0 | 0 |\n",
    "| 2 | 0 | 48 | 14 |\n",
    "\n",
    "## Cross tabulation with pandas\n",
    "- Clusters vs species is a \"cross-tabulation\"\n",
    "- Use the `pandas` library\n",
    "- Given the species of each sample as a list `species`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(species)"
   ]
  },
  {
   "source": [
    "## Alining lables and species"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'labels': labels, 'species': species})\n",
    "print(df)"
   ]
  },
  {
   "source": [
    "| | labels | species |\n",
    "| :-: | :-: | :-: |\n",
    "| 0 | 1 | setosa |\n",
    "| 1 | 1 | setosa |\n",
    "| 2 | 2 | versicolor |\n",
    "| 3 | 3 | virginica |\n",
    "| 4 | 1 | setosa |\n",
    "\n",
    "## Crosstab of labels and species"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.crosstab(df['labels'], df['species'])\n",
    "print(ct)"
   ]
  },
  {
   "source": [
    "| species | setosa | versicolor | virginica |\n",
    "| :-: | :-: | :-: | :-: |\n",
    "| 0 | 0 | 2 | 56 |\n",
    "| 1 | 50 | 0 | 0 |\n",
    "| 2 | 0 | 48 | 14 |\n",
    "\n",
    "How to evaluate a clustering, if there were no species information?\n",
    "\n",
    "## Measuring clustering quality\n",
    "- Using only samples and their cluster labels\n",
    "- A good clustering has tight clusters\n",
    "- Samples in each cluster bunched together\n",
    "\n",
    "## Inertia measures clustering quality\n",
    "- Measures how spread out the clusters are (lower is better)\n",
    "- Distance from each sample to centroid of its cluster\n",
    "- After `fit()`, available as attribute `inertia_`\n",
    "- k-means attempts to minimize the inertia when choosing clusters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=3)\n",
    "model.fit(samples)\n",
    "print(model.inertia_)"
   ]
  },
  {
   "source": [
    "## The number of clusters\n",
    "- Clusterings of the iris dataset with different numbers of clusters\n",
    "- More clusters means lowers inertia\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='image/Screenshot 2021-02-18 024118.png'>\n",
    "</p>\n",
    "\n",
    "## How many clusters to choose?\n",
    "- A good clustering has tight clusters (so low inertia)\n",
    "- ... but not too many clusters!\n",
    "- Choose an \"elbow\" in the inertia plot\n",
    "- Where inertia begins to decrease more slowly\n",
    "- E.g., for iris dataset, 3 is a good choice"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise IV: How many clusters of grain?\n",
    "\n",
    "In the video, you learned how to choose a good number of clusters for a dataset using the k-means inertia graph. You are given an array `samples` containing the measurements (such as area, perimeter, length, and several others) of samples of grain. What's a good number of clusters in this case?\n",
    "\n",
    "`KMeans` and PyPlot (`plt`) have already been imported for you.\n",
    "\n",
    "This dataset was sourced from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/seeds).\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- For each of the given values of `k`, perform the following steps:\n",
    "- Create a `KMeans` instance called `model` with `k` clusters.\n",
    "- Fit the model to the grain data `samples`.\n",
    "- Append the value of the `inertia_` attribute of `model` to the list `inertias`.\n",
    "- The code to plot `ks` vs `inertias` has been written for you, so hit 'Submit Answer' to see the plot!\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1, 6)\n",
    "inertias = []\n",
    "\n",
    "for k in ks:\n",
    "    # Create a KMeans instance with k clusters: model\n",
    "    model = KMeans(n_clusters=k)\n",
    "    \n",
    "    # Fit model to samples\n",
    "    model.fit(samples)\n",
    "    \n",
    "    # Append the inertia to the list of inertias\n",
    "    inertias.append(model.inertia_)\n",
    "    \n",
    "# Plot ks vs inertias\n",
    "plt.plot(ks, inertias, '-o')\n",
    "plt.xlabel('number of clusters, k')\n",
    "plt.ylabel('inertia')\n",
    "plt.xticks(ks)\n",
    "plt.show()\n"
   ]
  },
  {
   "source": [
    "## Plot\n",
    "\n",
    "<p align='center'>\n",
    "    <img src='image/[2021-02-18] 025003.svg'>\n",
    "</p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KMeans model with 3 clusters: model\n",
    "model = KMeans(n_clusters=3)\n",
    "\n",
    "# Use fit_predict to fit model and obtain cluster labels: labels\n",
    "labels = model.fit_predict(samples)\n",
    "\n",
    "# Create a DataFrame with labels and varieties as columns: df\n",
    "df = pd.DataFrame({'labels': labels, 'varieties': varieties})\n",
    "\n",
    "# Create crosstab: ct\n",
    "ct = pd.crosstab(df['labels'], df['varieties'])\n",
    "\n",
    "# Display ct\n",
    "print(ct)\n"
   ]
  }
 ]
}