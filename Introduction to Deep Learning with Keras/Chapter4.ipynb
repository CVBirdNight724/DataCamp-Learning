{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Advanced Model Architectures\n",
    "\n",
    "It's time to get introduced to more advanced architectures! You will create an autoencoder to reconstruct noisy images, visualize convolutional neural network activations, use deep pre-trained models to classify images and learn more about recurrent neural networks and working with text as you build a network that predicts the next word in a sentence."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# (1) Tensors, layers and autoencoders\n",
    "\n",
    "## Accesing Keras layers\n",
    "\n",
    "```\n",
    "# Accessing the first layer of a Keras model\n",
    "first_layer = model.layers[0]\n",
    "# Printing the layer, and its input, output and weights\n",
    "print(first_layer.input)\n",
    "print(first_layer.output)\n",
    "print(first_layer.weights)\n",
    "```\n",
    "\n",
    "## What are tensors?\n",
    "\n",
    "```\n",
    "# Define a rank 2 tensor (2 dimensions)\n",
    "T2 = [[1, 2, 3], \n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9]]\n",
    "# Define a rank 3 tensor (3 dimensions)\n",
    "T3 = [[1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9],\n",
    "        \n",
    "        [10, 11, 12],\n",
    "        [13, 14, 15],\n",
    "        [16, 17, 18],\n",
    "        \n",
    "        [19, 20, 21],\n",
    "        [22, 23, 24],\n",
    "        [25, 26, 27]]\n",
    "```\n",
    "\n",
    "```\n",
    "# Import Keras backend\n",
    "import keras.backend as K\n",
    "# Get the input and output tensors of a model layer\n",
    "inp = model.layers[0].input\n",
    "out = model.layers[0].output\n",
    "# Function that maps layer inputs to outputs\n",
    "inp_to_out = K.function([inp], [out])\n",
    "# We pass and input and get the output we'd get in that first layer\n",
    "print(inp_to_out([X_train]))\n",
    "```\n",
    "\n",
    "## it's time to introduce a new architecture\n",
    "\n",
    "## Auto encoders!\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-29 234520.png\">\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-29 234600.png\">\n",
    "\n",
    "## Autoencoder use cases\n",
    "\n",
    "- Dimensionality reduction:\n",
    "    - Smaller dimensional space representation of our inputs\n",
    "- De-noising data:\n",
    "    - If trained with clean data, irrelevant noise will be filtered out during reconstruction\n",
    "- Anomaly detection:\n",
    "    - A poor reconstruction will result when the model is fed with unseen inputs.\n",
    "\n",
    "## Building a simple autoencoder\n",
    "\n",
    "```\n",
    "# Instantiate a sequential model\n",
    "autoencoder = Sequential()\n",
    "# Add a hidden layer of 4 neurons and an input layer of 100\n",
    "autoencoder.add(Dense(4, input_shape=(100,), activation='relu'))\n",
    "# Add an output layer of 100 neurons\n",
    "autoencoder.add(Dense(100, activation='sigmoid'))\n",
    "# Compile your model with the appropiate loss\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "```\n",
    "\n",
    "## Breaking it into an encoder\n",
    "\n",
    "```\n",
    "# Building a separate model to encode inputs\n",
    "encoder = Sequential()\n",
    "encoder.add(autoencoder.layers[0])\n",
    "# Predicting returns the four hidden layer neuron outputs\n",
    "encoder.predict(X_test)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise I: It's a flow of tensors\n",
    "\n",
    "If you have already built a model, you can use the `model.layers` and the `keras.backend` to build functions that, provided with a valid input tensor, return the corresponding output tensor.\n",
    "\n",
    "This is a useful tool when we want to obtain the output of a network at an intermediate layer.\n",
    "\n",
    "For instance, if you get the input and output from the first layer of a network, you can build an `inp_to_out` function that returns the result of carrying out forward propagation through only the first layer for a given input tensor.\n",
    "\n",
    "So that's what you're going to do right now!\n",
    "\n",
    "`X_test` from the **Banknote Authentication** dataset and its `model` are preloaded. Type `model.summary()` in the console to check it.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Import `keras.backend` as `K`.\n",
    "- Use the `model.layers` list to get a reference to the input and output of the first layer.\n",
    "- Use `K.function()` to define a function that maps inp to out.\n",
    "- Print the results of passing `X_test` through the 1st layer.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keras backend\n",
    "import keras.backend as K\n",
    "\n",
    "# Input tensor from the 1st layer of the model\n",
    "inp = model.layers[0].input\n",
    "\n",
    "# Output tensor from the 1st layer of the model\n",
    "out = model.layers[0].output\n",
    "\n",
    "# Define a function from inputs to outputs\n",
    "inp_to_out = K.function([inp], [out])\n",
    "\n",
    "# Print the results of passing X_test through the 1st layer\n",
    "print(inp_to_out([X_test]))"
   ]
  },
  {
   "source": [
    "# Exercise II: Neural separation\n",
    "\n",
    "Put on your gloves because you're going to perform brain surgery!\n",
    "\n",
    "Neurons learn by updating their weights to output values that help them better distinguish between the different output classes in your dataset. You will make use of the `inp_to_out()` function you just built to visualize the output of two neurons in the first layer of the **Banknote Authentication** `model` as it learns.\n",
    "\n",
    "The `model` you built in chapter 2 is ready for you to use, just like `X_test` and `y_test`. Paste `show_code(plot)` in the console if you want to check `plot()`.\n",
    "\n",
    "You're performing heavy duty, once all is done, click through the graphs to watch the separation live!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Use the previously defined `inp_to_out()` function to get the outputs of the first layer when fed with `X_test`.\n",
    "- Use the `model.evaluate()` method to obtain the validation accuracy for the test dataset at each epoch.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "for i in range(0, 21):\n",
    "  \t# Train model for 1 epoch\n",
    "    h = model.fit(X_train, y_train, batch_size = 16, epochs = 1, verbose = 0)\n",
    "    if i%4==0: \n",
    "      # Get the output of the first layer\n",
    "      layer_output = inp_to_out([X_test])[0]\n",
    "      \n",
    "      # Evaluate model accuracy for this epoch\n",
    "      test_accuracy = model.evaluate(X_test, y_test)[1] \n",
    "      \n",
    "      # Plot 1st vs 2nd neuron output\n",
    "      plot()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## test_accuracy plot\n",
    "<img src=\"image/2021-01-30  001134.svg\" width=40%> \n",
    "\n",
    "<img src=\"image/2021-01-30  001721.svg\" width=40%>\n",
    "\n",
    "<img src=\"image/2021-01-30  001734.svg\" width=40%>\n",
    "\n",
    "<img src=\"image/2021-01-30  001751.svg\" width=40%>\n",
    "\n",
    "<img src=\"image/2021-01-30  001805.svg\" width=40%>\n",
    "\n",
    "<img src=\"image/2021-01-30  001823.svg\" width=40%>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise II: Building an autoencoder\n",
    "\n",
    "Autoencoders have several interesting applications like anomaly detection or image denoising. They aim at producing an output identical to its inputs. The input will be compressed into a lower dimensional space, **encoded**. The model then learns to **decode** it back to its original form.\n",
    "\n",
    "You will encode and decode the **MNIST** dataset of handwritten digits, the hidden layer will encode a 32-dimensional representation of the image, which originally consists of 784 pixels (28 x 28). The autoencoder will essentially learn to turn the 784 pixels original image into a compressed 32 pixels image and learn how to use that encoded representation to bring back the original 784 pixels image.\n",
    "\n",
    "The `Sequential` model and `Dense` layers are ready for you to use.\n",
    "\n",
    "Let's build an autoencoder!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Create a `Sequential` model.\n",
    "- Add a dense layer with as many neurons as the encoded image dimensions and `input_shape` the number of pixels in the original image.\n",
    "- Add a final layer with as many neurons as pixels in the input image.\n",
    "- Compile your `autoencoder` using `adadelta` as an optimizer and `binary_crossentropy` loss, then summarise it.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Start with a sequential model\n",
    "autoencoder = Sequential()\n",
    "\n",
    "# Add a dense layer with input the original image pixels and neurons the encoded representation\n",
    "autoencoder.add(Dense(32, input_shape=(784, ), activation=\"relu\"))\n",
    "\n",
    "# Add an output layer with as many neurons as the orginal image pixels\n",
    "autoencoder.add(Dense(784, activation = \"sigmoid\"))\n",
    "\n",
    "# Compile your model with adadelta\n",
    "autoencoder.compile(optimizer = 'adadelta', loss = 'binary_crossentropy')\n",
    "\n",
    "# Summarize your model structure\n",
    "autoencoder.summary()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# Exercise III: De-noising like an autoencoder\n",
    "\n",
    "Okay, you have just built an `autoencoder` model. Let's see how it handles a more challenging task.\n",
    "\n",
    "First, you will build a model that encodes images, and you will check how different digits are represented with `show_encodings()`. To build the encoder you will make use of your `autoencoder`, that has already being trained. You will just use the first half of the network, which contains the input and the bottleneck output. That way, you will obtain a 32 number output which represents the encoded version of the input image.\n",
    "\n",
    "Then, you will apply your `autoencoder` to noisy images from `MNIST`, it should be able to clean the noisy artifacts.\n",
    "\n",
    "`X_test_noise` is loaded in your workspace. The digits in this noisy dataset look like this:\n",
    "\n",
    "<img src=\"image/model_chapter2_binary_classification.jfif\">\n",
    "\n",
    "Apply the power of the autoencoder!\n",
    "\n",
    "### Instructions 1/2\n",
    "\n",
    "- Build an `encoder` model with the first layer of your trained `autoencoder` model.\n",
    "- Predict on `X_test_noise` with your `encoder` and show the results with `show_encodings()`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your encoder by using the first layer of your autoencoder\n",
    "encoder = Sequential()\n",
    "encoder.add(autoencoder.layers[0])\n",
    "\n",
    "# Encode the noisy images and show the encodings for your favorite number [0-9]\n",
    "encodings = encoder.predict(X_test_noise)\n",
    "show_encodings(encodings, number = 1)"
   ]
  },
  {
   "source": [
    "### Instructions 2/2\n",
    "\n",
    "- Predict on `X_test_noise` with your `autoencoder`, this will effectively perform both the encoding and decoding.\n",
    "- Plot noisy vs decoded images with `compare_plot()`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your encoder by using the first layer of your autoencoder\n",
    "encoder = Sequential()\n",
    "encoder.add(autoencoder.layers[0])\n",
    "\n",
    "# Encode the noisy images and show the encodings for your favorite number [0-9]\n",
    "encodings = encoder.predict(X_test_noise)\n",
    "show_encodings(encodings, number = 1)\n",
    "\n",
    "# Predict on the noisy images with your autoencoder\n",
    "decoded_imgs = autoencoder.predict(X_test_noise)\n",
    "\n",
    "# Plot noisy vs decoded images\n",
    "compare_plot(X_test_noise, decoded_imgs)"
   ]
  },
  {
   "source": [
    "## Plot noisy vs Decoded\n",
    "\n",
    "<img src=\"image/2021-01-30  005014.svg\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}