{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Advanced Model Architectures\n",
    "\n",
    "It's time to get introduced to more advanced architectures! You will create an autoencoder to reconstruct noisy images, visualize convolutional neural network activations, use deep pre-trained models to classify images and learn more about recurrent neural networks and working with text as you build a network that predicts the next word in a sentence."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# (1) Tensors, layers and autoencoders\n",
    "\n",
    "## Accesing Keras layers\n",
    "\n",
    "```\n",
    "# Accessing the first layer of a Keras model\n",
    "first_layer = model.layers[0]\n",
    "# Printing the layer, and its input, output and weights\n",
    "print(first_layer.input)\n",
    "print(first_layer.output)\n",
    "print(first_layer.weights)\n",
    "```\n",
    "\n",
    "## What are tensors?\n",
    "\n",
    "```\n",
    "# Define a rank 2 tensor (2 dimensions)\n",
    "T2 = [[1, 2, 3], \n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9]]\n",
    "# Define a rank 3 tensor (3 dimensions)\n",
    "T3 = [[1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9],\n",
    "        \n",
    "        [10, 11, 12],\n",
    "        [13, 14, 15],\n",
    "        [16, 17, 18],\n",
    "        \n",
    "        [19, 20, 21],\n",
    "        [22, 23, 24],\n",
    "        [25, 26, 27]]\n",
    "```\n",
    "\n",
    "```\n",
    "# Import Keras backend\n",
    "import keras.backend as K\n",
    "# Get the input and output tensors of a model layer\n",
    "inp = model.layers[0].input\n",
    "out = model.layers[0].output\n",
    "# Function that maps layer inputs to outputs\n",
    "inp_to_out = K.function([inp], [out])\n",
    "# We pass and input and get the output we'd get in that first layer\n",
    "print(inp_to_out([X_train]))\n",
    "```\n",
    "\n",
    "## it's time to introduce a new architecture\n",
    "\n",
    "## Auto encoders!\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-29 234520.png\">\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-29 234600.png\">\n",
    "\n",
    "## Autoencoder use cases\n",
    "\n",
    "- Dimensionality reduction:\n",
    "    - Smaller dimensional space representation of our inputs\n",
    "- De-noising data:\n",
    "    - If trained with clean data, irrelevant noise will be filtered out during reconstruction\n",
    "- Anomaly detection:\n",
    "    - A poor reconstruction will result when the model is fed with unseen inputs.\n",
    "\n",
    "## Building a simple autoencoder\n",
    "\n",
    "```\n",
    "# Instantiate a sequential model\n",
    "autoencoder = Sequential()\n",
    "# Add a hidden layer of 4 neurons and an input layer of 100\n",
    "autoencoder.add(Dense(4, input_shape=(100,), activation='relu'))\n",
    "# Add an output layer of 100 neurons\n",
    "autoencoder.add(Dense(100, activation='sigmoid'))\n",
    "# Compile your model with the appropiate loss\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "```\n",
    "\n",
    "## Breaking it into an encoder\n",
    "\n",
    "```\n",
    "# Building a separate model to encode inputs\n",
    "encoder = Sequential()\n",
    "encoder.add(autoencoder.layers[0])\n",
    "# Predicting returns the four hidden layer neuron outputs\n",
    "encoder.predict(X_test)\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise I: It's a flow of tensors\n",
    "\n",
    "If you have already built a model, you can use the `model.layers` and the `keras.backend` to build functions that, provided with a valid input tensor, return the corresponding output tensor.\n",
    "\n",
    "This is a useful tool when we want to obtain the output of a network at an intermediate layer.\n",
    "\n",
    "For instance, if you get the input and output from the first layer of a network, you can build an `inp_to_out` function that returns the result of carrying out forward propagation through only the first layer for a given input tensor.\n",
    "\n",
    "So that's what you're going to do right now!\n",
    "\n",
    "`X_test` from the **Banknote Authentication** dataset and its `model` are preloaded. Type `model.summary()` in the console to check it.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Import `keras.backend` as `K`.\n",
    "- Use the `model.layers` list to get a reference to the input and output of the first layer.\n",
    "- Use `K.function()` to define a function that maps inp to out.\n",
    "- Print the results of passing `X_test` through the 1st layer.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keras backend\n",
    "import keras.backend as K\n",
    "\n",
    "# Input tensor from the 1st layer of the model\n",
    "inp = model.layers[0].input\n",
    "\n",
    "# Output tensor from the 1st layer of the model\n",
    "out = model.layers[0].output\n",
    "\n",
    "# Define a function from inputs to outputs\n",
    "inp_to_out = K.function([inp], [out])\n",
    "\n",
    "# Print the results of passing X_test through the 1st layer\n",
    "print(inp_to_out([X_test]))"
   ]
  },
  {
   "source": [
    "# Exercise II: Neural separation\n",
    "\n",
    "Put on your gloves because you're going to perform brain surgery!\n",
    "\n",
    "Neurons learn by updating their weights to output values that help them better distinguish between the different output classes in your dataset. You will make use of the `inp_to_out()` function you just built to visualize the output of two neurons in the first layer of the **Banknote Authentication** `model` as it learns.\n",
    "\n",
    "The `model` you built in chapter 2 is ready for you to use, just like `X_test` and `y_test`. Paste `show_code(plot)` in the console if you want to check `plot()`.\n",
    "\n",
    "You're performing heavy duty, once all is done, click through the graphs to watch the separation live!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Use the previously defined `inp_to_out()` function to get the outputs of the first layer when fed with `X_test`.\n",
    "- Use the `model.evaluate()` method to obtain the validation accuracy for the test dataset at each epoch.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "for i in range(0, 21):\n",
    "  \t# Train model for 1 epoch\n",
    "    h = model.fit(X_train, y_train, batch_size = 16, epochs = 1, verbose = 0)\n",
    "    if i%4==0: \n",
    "      # Get the output of the first layer\n",
    "      layer_output = inp_to_out([X_test])[0]\n",
    "      \n",
    "      # Evaluate model accuracy for this epoch\n",
    "      test_accuracy = model.evaluate(X_test, y_test)[1] \n",
    "      \n",
    "      # Plot 1st vs 2nd neuron output\n",
    "      plot()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## test_accuracy plot\n",
    "<img src=\"image/2021-01-30  001134.svg\" width=40%> \n",
    "\n",
    "<img src=\"image/2021-01-30  001721.svg\" width=40%>\n",
    "\n",
    "<img src=\"image/2021-01-30  001734.svg\" width=40%>\n",
    "\n",
    "<img src=\"image/2021-01-30  001751.svg\" width=40%>\n",
    "\n",
    "<img src=\"image/2021-01-30  001805.svg\" width=40%>\n",
    "\n",
    "<img src=\"image/2021-01-30  001823.svg\" width=40%>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise II: Building an autoencoder\n",
    "\n",
    "Autoencoders have several interesting applications like anomaly detection or image denoising. They aim at producing an output identical to its inputs. The input will be compressed into a lower dimensional space, **encoded**. The model then learns to **decode** it back to its original form.\n",
    "\n",
    "You will encode and decode the **MNIST** dataset of handwritten digits, the hidden layer will encode a 32-dimensional representation of the image, which originally consists of 784 pixels (28 x 28). The autoencoder will essentially learn to turn the 784 pixels original image into a compressed 32 pixels image and learn how to use that encoded representation to bring back the original 784 pixels image.\n",
    "\n",
    "The `Sequential` model and `Dense` layers are ready for you to use.\n",
    "\n",
    "Let's build an autoencoder!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Create a `Sequential` model.\n",
    "- Add a dense layer with as many neurons as the encoded image dimensions and `input_shape` the number of pixels in the original image.\n",
    "- Add a final layer with as many neurons as pixels in the input image.\n",
    "- Compile your `autoencoder` using `adadelta` as an optimizer and `binary_crossentropy` loss, then summarise it.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Start with a sequential model\n",
    "autoencoder = Sequential()\n",
    "\n",
    "# Add a dense layer with input the original image pixels and neurons the encoded representation\n",
    "autoencoder.add(Dense(32, input_shape=(784, ), activation=\"relu\"))\n",
    "\n",
    "# Add an output layer with as many neurons as the orginal image pixels\n",
    "autoencoder.add(Dense(784, activation = \"sigmoid\"))\n",
    "\n",
    "# Compile your model with adadelta\n",
    "autoencoder.compile(optimizer = 'adadelta', loss = 'binary_crossentropy')\n",
    "\n",
    "# Summarize your model structure\n",
    "autoencoder.summary()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# Exercise III: De-noising like an autoencoder\n",
    "\n",
    "Okay, you have just built an `autoencoder` model. Let's see how it handles a more challenging task.\n",
    "\n",
    "First, you will build a model that encodes images, and you will check how different digits are represented with `show_encodings()`. To build the encoder you will make use of your `autoencoder`, that has already being trained. You will just use the first half of the network, which contains the input and the bottleneck output. That way, you will obtain a 32 number output which represents the encoded version of the input image.\n",
    "\n",
    "Then, you will apply your `autoencoder` to noisy images from `MNIST`, it should be able to clean the noisy artifacts.\n",
    "\n",
    "`X_test_noise` is loaded in your workspace. The digits in this noisy dataset look like this:\n",
    "\n",
    "<img src=\"image/model_chapter2_binary_classification.jfif\">\n",
    "\n",
    "Apply the power of the autoencoder!\n",
    "\n",
    "### Instructions 1/2\n",
    "\n",
    "- Build an `encoder` model with the first layer of your trained `autoencoder` model.\n",
    "- Predict on `X_test_noise` with your `encoder` and show the results with `show_encodings()`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your encoder by using the first layer of your autoencoder\n",
    "encoder = Sequential()\n",
    "encoder.add(autoencoder.layers[0])\n",
    "\n",
    "# Encode the noisy images and show the encodings for your favorite number [0-9]\n",
    "encodings = encoder.predict(X_test_noise)\n",
    "show_encodings(encodings, number = 1)"
   ]
  },
  {
   "source": [
    "### Instructions 2/2\n",
    "\n",
    "- Predict on `X_test_noise` with your `autoencoder`, this will effectively perform both the encoding and decoding.\n",
    "- Plot noisy vs decoded images with `compare_plot()`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your encoder by using the first layer of your autoencoder\n",
    "encoder = Sequential()\n",
    "encoder.add(autoencoder.layers[0])\n",
    "\n",
    "# Encode the noisy images and show the encodings for your favorite number [0-9]\n",
    "encodings = encoder.predict(X_test_noise)\n",
    "show_encodings(encodings, number = 1)\n",
    "\n",
    "# Predict on the noisy images with your autoencoder\n",
    "decoded_imgs = autoencoder.predict(X_test_noise)\n",
    "\n",
    "# Plot noisy vs decoded images\n",
    "compare_plot(X_test_noise, decoded_imgs)"
   ]
  },
  {
   "source": [
    "## Plot noisy vs Decoded\n",
    "\n",
    "<img src=\"image/2021-01-30  005014.svg\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# (2) Intro to CNNs\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-30 010625.png\">\n",
    "<img src=\"image/Screenshot 2021-01-30 010655.png\">\n",
    "<img src=\"image/Screenshot 2021-01-30 010718.png\">\n",
    "<img src=\"image/Screenshot 2021-01-30 010737.png\">\n",
    "\n",
    "```\n",
    "# Import Conv2D layer and FLatten from keras layers\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "# Instantiate your model as usual\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer with 32 filters of size 3x3\n",
    "model.add(Conv2D(filters=32, \n",
    "                kernel_size=3, \n",
    "                input_shape=(28, 28, 1),\n",
    "                activation='relu'))\n",
    "# Add another convolutional layer\n",
    "model.add(Conv2D(8, kernel_size=3, activation='relu'))\n",
    "\n",
    "# Flatten the output of the previous layer\n",
    "model.add(Flatten())\n",
    "# End this multiclass model with 3 outputs and softmax\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "```\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-30 011641.png\">\n",
    "\n",
    "## Pre-processing images for ResNet50\n",
    "\n",
    "```\n",
    "# Import image from keras preprocessing\n",
    "from keras.preprocessing import image\n",
    "# Import preprocessing_input from keras applications resnet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "# Load the image with the right target size for your model\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "# Turn it into an array\n",
    "img = image.img_to_array(img)\n",
    "# Expand the dimensions so that it's understood by our network:\n",
    "# img.shape turns from (224, 224, 3) into (1, 224, 224, 3)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "# Pre-process the img in the same way training images were\n",
    "img = preprocess_input(img)\n",
    "```\n",
    "\n",
    "## Using the ResNet50 model in Keras\n",
    "\n",
    "```\n",
    "# Import ResNet50 and decode_predictions from keras.applications.resnet50\n",
    "from keras.applications.resnet50 import ResNet50, decode_predictions\n",
    "# Instantiate a ResNet50 model with imagement weights\n",
    "model = ResNet50(weights='imagenet')\n",
    "# Predict with ResNet50 on our img\n",
    "preds = model.Predict(img)\n",
    "# Decode predictions and print it\n",
    "print('Predicted: ', decode_predictions(preds, top=1)[0])\n",
    "```\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-30 012635.png\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise IV: Building a CNN model\n",
    "\n",
    "Building a CNN model in Keras isn't much more difficult than building any of the models you've already built throughout the course! You just need to make use of convolutional layers.\n",
    "\n",
    "You're going to build a shallow convolutional `model` that classifies the **MNIST** digits dataset. The same one you de-noised with your autoencoder! The images are 28 x 28 pixels and **just have one channel**, since they are black and white pictures.\n",
    "\n",
    "Go ahead and build this small convolutional model!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Import the `Conv2D` and `Flatten layers` and instantiate your model.\n",
    "- Add a first convolutional layer with 32 filters of size 3x3 and the corresponding 3D tuple as `input_shape`.\n",
    "- Add a second convolutional layer with 16 filters of size 3x3 with relu activation.\n",
    "- Flatten the previous layer output to create a one-dimensional vector.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Conv2D and Flatten layers and instantiate model\n",
    "from keras.layers import Conv2D,Flatten\n",
    "model = Sequential()\n",
    "\n",
    "# Add a convolutional layer of 32 filters of size 3x3\n",
    "model.add(Conv2D(32, kernel_size = 3, input_shape = (28, 28, 1), activation = 'relu'))\n",
    "\n",
    "# Add a convolutional layer of 16 filters of size 3x3\n",
    "model.add(Conv2D(16, kernel_size = 3, activation = 'relu'))\n",
    "\n",
    "# Flatten the previous layer output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add as many outputs as classes with softmax activation\n",
    "model.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "source": [
    "# Exercise V: Looking at convolutions\n",
    "\n",
    "Inspecting the activations of a convolutional layer is a cool thing. You have to do it at least once in your lifetime!\n",
    "\n",
    "To do so, you will build a new model with the Keras `Model` object, which takes in a list of inputs and a list of outputs. The output you will provide to this new model is the first convolutional layer outputs when given an **MNIST** digit as input image.\n",
    "\n",
    "The convolutional `model` you built in the previous exercise has already been trained for you. It can now correctly classify **MNIST** handwritten images. You can check it with `model.summary()` in the console.\n",
    "\n",
    "Let's look at the convolutional masks that were learned in the first convolutional layer of this model!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Obtain a reference to the outputs of the first convolutional layer in the model.\n",
    "- Build a new model using the model's first layer input and the `first_layer_output as outputs`.\n",
    "- Use this `first_layer_model` to predict on `X_test`.\n",
    "- Plot the activations of the first digit of `X_test` for the **15th** and the **18th** neuron filter.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain a reference to the outputs of the first layer\n",
    "first_layer_output = model.layers[0].output\n",
    "\n",
    "# Build a model using the model's input and the first layer output\n",
    "first_layer_model = Model(inputs = model.layers[0].input, outputs = first_layer_output)\n",
    "\n",
    "# Use this model to predict on X_test\n",
    "activations = first_layer_model.predict(X_test)\n",
    "\n",
    "# Plot the activations of first digit of X_test for the 15th filter\n",
    "axs[0].matshow(activations[0,:,:,14], cmap = 'viridis')\n",
    "\n",
    "# Do the same but for the 18th filter now\n",
    "axs[1].matshow(activations[0,:,:,18], cmap = 'viridis')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Plot filter at 15th vs 18th\n",
    "\n",
    "<img src=\"image/2021-01-30  013753.svg\" weight=50%>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise VI: Preparing your input image\n",
    "\n",
    "The original **ResNet50** model was trained with images of size **224 x 224 pixels** and a number of preprocessing operations; like the subtraction of the mean pixel value in the training set for all training images. You need to pre-process the images you want to predict on in the same way.\n",
    "\n",
    "When predicting on a single image you need it to fit the model's input shape, which in this case looks like this: (batch-size, width, height, channels), `np.expand_dims` with parameter `axis = 0` adds the batch-size dimension, representing that a single image will be passed to predict. This batch-size dimension value is 1, since we are only predicting on one image.\n",
    "\n",
    "You will go over these preprocessing steps as you prepare this dog's (named Ivy) image into one that can be classified by **ResNet50**.\n",
    "\n",
    "<img src=\"image/dog.png\">\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Import `image` from `keras.preprocessing` and `preprocess_input` from `keras.applications.resnet50`.\n",
    "- Load the image with the right `target_size` for your model.\n",
    "- Turn it into an array with `image.img_to_array()`.\n",
    "- Pre-process `img_expanded` the same way the original ResNet50 training images were processed with `preprocess_input()`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import image and preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Load the image with the right target size for your model\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "# Turn it into an array\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "# Expand the dimensions of the image, this is so that it fits the expected model input format\n",
    "img_expanded = np.expand_dims(img_array, axis = 0)\n",
    "\n",
    "# Pre-process the img in the same way original images were\n",
    "img_ready = preprocess_input(img_expanded)"
   ]
  },
  {
   "source": [
    "# Exercise VII: Using a real world model\n",
    "\n",
    "Okay, so Ivy's picture is ready to be used by **ResNet50**. It is stored in `img_ready` and now looks like this:\n",
    "\n",
    "<img src=\"image/dog_processed.png\">\n",
    "\n",
    "**ResNet50** is a model trained on the Imagenet dataset that is able to distinguish between 1000 different labeled objects. **ResNet50** is a deep model with 50 layers, you can check it in 3D [here](https://tensorspace.org/html/playground/resnet50.html).\n",
    "\n",
    "`ResNet50` and `decode_predictions` have both been imported from `keras.applications.resnet50` for you.\n",
    "\n",
    "It's time to use this trained model to find out Ivy's breed!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Instantiate a `ResNet50` model, setting the weights parameter to be `'imagenet'`.\n",
    "- Use the `model` to predict on your processed image.\n",
    "- Decode the first 3 predictions with `decode_predictions()`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a ResNet50 model with 'imagenet' weights\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# Predict with ResNet50 on your already processed img\n",
    "preds = model.predict(img_ready)\n",
    "\n",
    "# Decode the first 3 predictions\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "source": [
    "# (4) Intro to LSTMs\n",
    "\n",
    "## What are RNNs?\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-30 015848.png\">\n",
    "<img src=\"image/Screenshot 2021-01-30 020019.png\">\n",
    "\n",
    "## When to use LSTMs?\n",
    "- Image captioning\n",
    "- Speech to text\n",
    "- Text translation\n",
    "- Document summarization\n",
    "- Text generation\n",
    "- Musical composition\n",
    "\n",
    "<img src=\"image/Screenshot 2021-01-30 020408.png\">\n",
    "<img src=\"image/Screenshot 2021-01-30 020423.png\">\n",
    "\n",
    "```\n",
    "text = 'Hi this is a small sentense'\n",
    "\n",
    "# We choose a sequence length\n",
    "seq_len = 3\n",
    "\n",
    "# Split text into a list of words\n",
    "words = text.split()\n",
    "```\n",
    "\n",
    "```\n",
    "# Make lines\n",
    "lines = []\n",
    "for i in range(seq_len, len(words) + 1):\n",
    "    line = ' '.join(words[i-seq_len:i])\n",
    "    lines.append(line)\n",
    "```\n",
    "\n",
    "```\n",
    "# Import Tokenizer from keras preprocessing text\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# Instantiate Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "# Fit it on the previous lines\n",
    "tokenizer.fit_on_texts(lines)\n",
    "# Turns the lines into numeric sequences\n",
    "sequences = tokenizer.texts_to_sequences(lines)\n",
    "```\n",
    "\n",
    "```\n",
    "print(tokenizer.index_word)\n",
    "```\n",
    "\n",
    "```\n",
    "# Import Dense, LSTM and Embedding layers\n",
    "from keras.layers import Dense, LSTM, Embedding\n",
    "model = Sequential()\n",
    "# Vocabulary size\n",
    "vocab_size = len(tokenizer.index_word) + 1\n",
    "# Starting with an embedding layer\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=8, input_length=2))\n",
    "# Adding an LSTM layer\n",
    "model.add(LSTM(8))\n",
    "\n",
    "# Adding a Dense hidden layer\n",
    "model.add(Dense(8, activation='relu'))\n",
    "# Adding an output layer with softmax\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Exercise VIII: Text prediction with LSTMs\n",
    "\n",
    "During the following exercises you will build a toy LSTM model that is able to predict the next word using a small text dataset. This dataset consist of cleaned quotes from the **The Lord of the Ring** movies. You can find them in the `text` variable.\n",
    "\n",
    "You will turn this `text` into `sequences` of **length 4** and make use of the Keras `Tokenizer` to prepare the features and labels for your model!\n",
    "\n",
    "The Keras `Tokenizer` is already imported for you to use. It assigns a unique number to each unique word, and stores the mappings in a dictionary. This is important since the model deals with numbers but we later will want to decode the output numbers back into words.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Split the text into an array of words using `.split()`.\n",
    "- Make sentences of 4 words each, moving one word at a time.\n",
    "- Instantiate a `Tokenizer()`, then fit it on the sentences with `.fit_on_texts()`.\n",
    "- Turn `sentences` into a sequence of numbers calling `.texts_to_sequences()`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text into an array of words \n",
    "words = text.split()\n",
    "\n",
    "# Make sentences of 4 words each, moving one word at a time\n",
    "sentences = []\n",
    "for i in range(4, len(words)):\n",
    "  sentences.append(' '.join(words[i-4:i]))\n",
    "\n",
    "# Instantiate a Tokenizer, then fit it on the sentences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "# Turn sentences into a sequence of numbers\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "print(\"Sentences: \\n {} \\n Sequences: \\n {}\".format(sentences[:5],sequences[:5]))"
   ]
  },
  {
   "source": [
    "# Exercise IX: Build your LSTM model\n",
    "\n",
    "You've already prepared your sequences of text. It's time to build your LSTM model!\n",
    "\n",
    "Remember your sequences had 4 words each, your model will be trained on the first three words of each sequence, predicting the 4th one. You are going to use an `Embedding` layer that will essentially learn to turn words into vectors. These vectors will then be passed to a simple `LSTM` layer. Our output is a `Dense` layer with as many neurons as words in the vocabulary and `softmax` activation. This is because we want to obtain the highest probable next word out of all possible words.\n",
    "\n",
    "The size of the vocabulary of words (the unique number of words) is stored in `vocab_size`.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Import the `Embedding`, `LSTM` and `Dense` layer from Keras layers.\n",
    "- Add an `Embedding()` layer of the vocabulary size, that will turn words into 8 number vectors and receive sequences of length 3.\n",
    "- Add a 32 neuron `LSTM()` layer.\n",
    "- Add a hidden `Dense()` layer of 32 neurons and an output layer of `vocab_size` neurons with `softmax`.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Embedding, LSTM and Dense layer\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Add an Embedding layer with the right parameters\n",
    "model.add(Embedding(input_dim = vocab_size, input_length = 3, output_dim = 8, ))\n",
    "\n",
    "# Add a 32 unit LSTM layer\n",
    "model.add(LSTM(32))\n",
    "\n",
    "# Add a hidden Dense layer of 32 units and an output layer of vocab_size with softmax\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "source": [
    "# Exercise X: Decode your predictions\n",
    "\n",
    "Your LSTM `model` has already been trained (details in the previous exercise success message) so that you don't have to wait. It's time to **define a function** that decodes its predictions. The trained `model` will be passed as a default parameter to this function.\n",
    "\n",
    "Since you are predicting on a model that uses the softmax function, numpy's `argmax()` can be used to obtain the index/position representing the most probable next word out of the output vector of probabilities.\n",
    "\n",
    "The `tokenizer` you previously created and fitted, is loaded for you. You will be making use of its internal `index_word` dictionary to turn the `model`'s next word prediction (which is an integer) into the actual written word it represents.\n",
    "\n",
    "You're very close to experimenting with your model!\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Use `texts_to_sequences()` to turn the `test_text` parameter into a sequence of numbers.\n",
    "- Get the model's next word prediction by passing in `test_seq` . The index/position representing the word with the highest probability is obtained by calling `.argmax(axis=1)[0]` on the numpy array of predictions.\n",
    "- Return the word that maps to the prediction using the tokenizer's `index_word` dictionary.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(test_text, model = model):\n",
    "  if len(test_text.split()) != 3:\n",
    "    print('Text input should be 3 words!')\n",
    "    return False\n",
    "  \n",
    "  # Turn the test_text into a sequence of numbers\n",
    "  test_seq = tokenizer.texts_to_sequences([test_text])\n",
    "  test_seq = np.array(test_seq)\n",
    "  \n",
    "  # Use the model passed as a parameter to predict the next word\n",
    "  pred = model.predict(test_seq).argmax(axis = 1)[0]\n",
    "  \n",
    "  # Return the word that maps to the prediction\n",
    "  return tokenizer.index_word[pred]"
   ]
  },
  {
   "source": [
    "# Exercise X: Test your model!\n",
    "\n",
    "The function you just built, `predict_text()`, is ready to use. Remember that the model object is already passed by default as the second parameter so you just need to provide the function with your 3 word sentences.\n",
    "\n",
    "Try out these strings on your LSTM model:\n",
    "\n",
    "    - `'meet revenge with'`\n",
    "    - `'the course of'`\n",
    "    - `'strength of the'`\n",
    "\n",
    "Which sentence could be made with the word output from the sentences above?\n",
    "\n",
    "### Possible Answers\n",
    "- A **worthless gnome** is **king**\n",
    "- **Revenge** is your **history** and **spirit** (T)\n",
    "- Take a **sword** and **ride** to **Florida**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# You're done!\n",
    "\n",
    "## What you've learned\n",
    "- Basics of a neural networks\n",
    "- Building sequential model\n",
    "- Building models for regression\n",
    "- Approaching binary classification, multi-class and multi-label problems with neural networks\n",
    "- Activation functions\n",
    "- Hyperparameter optimization\n",
    "- Autoencoders\n",
    "- De-noising images\n",
    "- CNN concepts\n",
    "- Use pre-trained models\n",
    "- Visualize convolutions\n",
    "- LSTMs concepts\n",
    "- Work with LSTMs and text\n",
    "- All this by using many different datasets and learning a lot of Keras utility functions.\n",
    "\n",
    "## What could you learn next\n",
    "- Go deeper into CNNs\n",
    "- GO deeper into LSTMs\n",
    "- Keras Functional API\n",
    "- Models that share layers, models with several branches\n",
    "- GANs: Generative Adversarial Networks\n",
    "- Deeplearning projects"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}